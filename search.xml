<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Vue-cli 目录结构笔记 及 一个简单电商项目的网页架构思路]]></title>
      <url>/2018/06/05/Vue-cli-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E7%AC%94%E8%AE%B0-%E5%8F%8A-%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%94%B5%E5%95%86%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%BD%91%E9%A1%B5%E6%9E%B6%E6%9E%84%E6%80%9D%E8%B7%AF/</url>
      <content type="html"><![CDATA[<p>学习了vue有一小段时间，期间中断去学习了java并且补了一下数据结构的基础，有点断层。跟着视频用vue2.0做了一个电商的小项目。思路稍微清晰了一些，但是因为中途转学其他的缘故，有一些东西还是忘掉了，这里总结一下使用vue-cli搭建项目的一些经验和教训。</p>
<p>首先是vue-cli的目录结构，这个是基于webpack的脚手架目录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">.</div><div class="line">|-- build                            // 项目构建(webpack)相关代码</div><div class="line">|   |-- build.js                     // 生产环境构建代码</div><div class="line">|   |-- check-version.js             // 检查node、npm等版本</div><div class="line">|   |-- utils.js                     // 构建工具相关</div><div class="line">|   |-- vue-loader.conf.js           // css加载器配置</div><div class="line">|   |-- webpack.base.conf.js         // webpack基础配置</div><div class="line">|   |-- webpack.dev.conf.js          // webpack开发环境配置</div><div class="line">|   |-- webpack.prod.conf.js         // webpack生产环境配置</div><div class="line">|-- config                           // 项目开发环境配置</div><div class="line">|   |-- dev.env.js                   // 开发环境变量</div><div class="line">|   |-- index.js                     // 项目一些配置变量(包括监听变量，打包路径等)</div><div class="line">|   |-- prod.env.js                  // 生产环境变量</div><div class="line">|   |-- test.env.js                  // 测试环境变量</div><div class="line">|-- node_modules                     //存放依赖的目录</div><div class="line">|-- src                              // 源码目录</div><div class="line">|   |-- assets                         // 静态资源（css文件，外部js文件）</div><div class="line">|   |-- components                     // vue公共组件</div><div class="line">|   |-- router                         // 路由配置</div><div class="line">|   |-- App.vue                        // 根组件</div><div class="line">|   |-- main.js                        // 入口文件，加载各种公共组件</div><div class="line">|-- static                           // 静态文件，比如一些图片，json数据等</div><div class="line">|-- test                             // 测试文件目录</div><div class="line">|-- .babelrc                         // ES6语法编译配置</div><div class="line">|-- .editorconfig                    // 定义代码格式</div><div class="line">|-- .gitignore                       // git上传需要忽略的文件格式</div><div class="line">|-- .postcssrc.js</div><div class="line">|-- README.md                        // 项目说明</div><div class="line">|-- index.html                       // 入口页面</div><div class="line">|-- package.json                     // 项目基本信息</div><div class="line">.</div></pre></td></tr></table></figure>
<p>当然不同版本的项目目录或者文件大同小异，基本都包括在上面了。</p>
<p>接下来讲一个平时用的比较多的网页排版及vue的大体配置。在此之前先介绍几个文件：</p>
<ol>
<li>index.html<br>一般只定义一个空的根节点，在main.js里面定义的实例将挂载在根节点下，内容都通过vue组件来填充。</li>
</ol>
<p><img src="/2018/06/05/Vue-cli-目录结构笔记-及-一个简单电商项目的网页架构思路/1.png" alt=""></p>
<ol>
<li><p>App.vue<br>App.vue 是个根组件。一个vue文件包括template,script,style三部分。<br>vue通常用es6来写，用export default导出。<br><code>&lt;style&gt;&lt;/style&gt;</code>默认是影响全局的，如需定义作用域只在该组件下起作用，需在标签上加scoped。<br>如要引入外部css文件，首先需给项目安装css-loader依赖包。使用import引入，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;style&gt;</div><div class="line"></div><div class="line">  import &apos;./assets/css/bootstrap.css&apos;</div><div class="line"></div><div class="line">&lt;/style&gt;</div></pre></td></tr></table></figure>
</li>
<li><p>main.js<br>main.js是个入口文件。<br>这里:<code>template: &#39;&lt;App/&gt;&#39;</code>表示用<code>&lt;app&gt;&lt;/app&gt;</code>替换index.html里面的<code>&lt;div id=&quot;app&quot;&gt;&lt;/div&gt;</code>。<br>这么做的目的很简单，<code>&lt;App /&gt;</code>他就是<code>App.vue</code>，template就是选择vue实例要加载哪个模板。最新的vue-cli脚手架模板现在是这个形式。App.vue是主程序，其他所有的.vue都是放在App.vue中，所以只需要加载App.vue就完全可以把其他的东西加载出来。<br><img src="/2018/06/05/Vue-cli-目录结构笔记-及-一个简单电商项目的网页架构思路/2.png" alt=""></p>
</li>
<li><p>router<br>router目录下的index.js即是路由配置文件</p>
<p><img src="/2018/06/05/Vue-cli-目录结构笔记-及-一个简单电商项目的网页架构思路/3.png" alt=""></p>
<p>router中可以设置多个路由，但是这里要先引入相应的组件，在进行设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">//引入Vue框架</div><div class="line">import Vue from &apos;vue&apos;</div><div class="line"></div><div class="line">//引入路由依赖</div><div class="line">import Router from &apos;vue-router&apos;</div><div class="line"></div><div class="line">//引入各个页面组件</div><div class="line">import IndexPage from &apos;./components/index&apos;</div><div class="line">import DetailPage from &apos;./components/detail.vue&apos;</div><div class="line">import DetailAnaPage from &apos;./components/detail/analysis&apos;</div><div class="line">import DetailPubPage from &apos;./components/detail/publish&apos;</div><div class="line">import DetailCouPage from &apos;./components/detail/count&apos;</div><div class="line">import DetailForPage from &apos;./components/detail/forecast&apos;</div><div class="line">import OrderListPage from &apos;./components/orderList&apos;</div><div class="line">Vue.use(Router)</div><div class="line"></div><div class="line">export default new Router(&#123;</div><div class="line">  mode: &apos;history&apos;,</div><div class="line">  routes: [</div><div class="line">    &#123;</div><div class="line">      path: &apos;/&apos;,</div><div class="line">      component: IndexPage</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      path: &apos;/orderList&apos;,</div><div class="line">      component: OrderListPage</div><div class="line">    &#125;,</div><div class="line">    &#123;</div><div class="line">      path: &apos;/detail&apos;,</div><div class="line">      component: DetailPage,</div><div class="line">      redirect: &apos;detail/analysis&apos;,</div><div class="line">      children: [</div><div class="line">        &#123;</div><div class="line">          path: &apos;forecast&apos;,</div><div class="line">          component: DetailForPage</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          path: &apos;analysis&apos;,</div><div class="line">          component: DetailAnaPage</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          path: &apos;publish&apos;,</div><div class="line">          component: DetailPubPage</div><div class="line">        &#125;,</div><div class="line">        &#123;</div><div class="line">          path: &apos;count&apos;,</div><div class="line">          component: DetailCouPage</div><div class="line">        &#125;</div><div class="line">      ]</div><div class="line">    &#125;</div><div class="line">  ]</div><div class="line">&#125;)</div></pre></td></tr></table></figure>
<p>这里介绍一个基础的vue模板构建思路：<br><img src="/2018/06/05/Vue-cli-目录结构笔记-及-一个简单电商项目的网页架构思路/5.png" alt=""></p>
<p><code>App.vue</code>如下，其中的router的配置可以参见上面的代码</p>
<p><img src="/2018/06/05/Vue-cli-目录结构笔记-及-一个简单电商项目的网页架构思路/4.png" alt="App.vue"><br>当然这里只设置了简单的内容，具体的方法和数据及样式根据不同的需求进行补充即可。</p>
<p>当然这只是一种简单的设计思路，做项目时可以用这个做为参考，但是不要被限制。</p>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> 前端 </tag>
            
            <tag> Vue </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（十）——图计算]]></title>
      <url>/2018/05/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%8D%81%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E8%AE%A1%E7%AE%97/</url>
      <content type="html"><![CDATA[<h1 id="图结构数据"><a href="#图结构数据" class="headerlink" title="图结构数据"></a>图结构数据</h1><p>•许多大数据都是以大规模图或网络的形式呈现<br>•许多非图结构的大数据，也常常会被转换为图模型后进行分析<br>•图数据结构很好地表达了数据之间的关联性<br>•关联性计算是大数据计算的核心——通过获得数据的关联性，可以从噪音很多的海量数据中抽取有用的信息</p>
<h1 id="传统图计算解决方案的不足之处"><a href="#传统图计算解决方案的不足之处" class="headerlink" title="传统图计算解决方案的不足之处"></a>传统图计算解决方案的不足之处</h1><p>很多传统的图计算算法都存在以下几个典型问题：<br>（1）常常表现出比较差的内存访问局部性<br>（2）针对单个顶点的处理工作过少<br>（3）计算过程中伴随着并行度的改变</p>
<p>针对大型图（比如社交网络和网络图）的计算问题，可能的解决方案及其不足之处具体如下：<br>• （1 ）为特定的图应用定制相应的分布式实现<br>• （2 ）基于现有的分布式计算平台进行图计算<br>• （3 ）使用单机的图算法库：比如BGL、LEAD、NetworkX、JDSL、Standford GraphBase和FGL等<br>• （4 ）使用已有的并行图计算系统：比如，ParallelBGL和CGM Graph，实现了很多并行图算法</p>
<h1 id="图计算通用软件"><a href="#图计算通用软件" class="headerlink" title="图计算通用软件"></a>图计算通用软件</h1><p>• 针对大型图的计算，目前通用的图计算软件主要包括两种：<br>– 第一种主要是 基于遍历算法 的、 实时的图数据库，如Neo4j、OrientDB、DEX和 Infinite Graph<br>– 第二种则是 以图顶点为中心的、基于消息传递批处理的并行引擎，如GoldenOrb、Giraph、Pregel和Hama，这些图处理软件主要是基于BSP模型实现的并行图处理系统</p>
<p>一次BSP(Bulk Synchronous Parallel Computing Model，又称“大同步”模型)计算过程包括一系列全局超步（所谓的超步就是计算中的一次迭代），每个超<br>步主要包括三个组件：<br>• 局部计算：每个参与的处理器都有自身的计算任务<br>• 通讯：处理器群相互交换数据<br>• 栅栏同步(Barrier Synchronization)：当一个处理器遇到“路障”（或栅栏），会等到其他所有处理器完成它们的计算步骤</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/1.png" alt=""></p>
<h1 id="Pregel"><a href="#Pregel" class="headerlink" title="Pregel"></a>Pregel</h1><p>•谷歌公司在2003年到2004年公布了GFS、MapReduce和BigTable<br>•谷歌在后Hadoop时代的新“三驾马车”<br>•Caffeine<br>•Dremel<br>•Pregel<br>•Pregel是一种基于BSP模型实现的并行图处理系统<br>•为了解决大型图的分布式计算问题，Pregel搭建了一套可扩展的、有容错机制的平台，该平台提供了一套非常灵活的API，可以描述各种各样的图计算<br>•Pregel作为分布式图计算的计算框架，主要用于图遍历、最短路径、PageRank计算等等</p>
<h1 id="Pregel图计算模型"><a href="#Pregel图计算模型" class="headerlink" title="Pregel图计算模型"></a>Pregel图计算模型</h1><h2 id="有向图和顶点"><a href="#有向图和顶点" class="headerlink" title="有向图和顶点"></a>有向图和顶点</h2><p>•Pregel计算模型以有向图作为输入<br>•有向图的每个顶点都有一个String类型的顶点ID<br>•每个顶点都有一个可修改的用户自定义值与之关联<br>•每条有向边都和其源顶点关联，并记录了其目标顶点ID<br>•边上有一个可修改的用户自定义值与之关联</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/2.png" alt=""></p>
<p>•在每个超步S中，图中的所有顶点都会并行执行相同的用户自定义函数<br>•每个顶点可以接收前一个超步(S-1)中发送给它的消息，修改其自身及其出射边的状态，并发送消息给其他顶点，甚至是修改整个图的拓扑结构<br>•在这种计算模式中，“边”并不是核心对象，在边上面不会运行相应的计算，只有顶点才会执行用户自定义函数进行相应计算</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/3.png" alt=""></p>
<h2 id="顶点之间的消息传递"><a href="#顶点之间的消息传递" class="headerlink" title="顶点之间的消息传递"></a>顶点之间的消息传递</h2><p>采用消息传递模型主要基于以下两个原因：<br>（1）消息传递具有足够的表达能力，没有必要使用远程读取或共享内存的方式<br>（2）有助于提升系统整体性能<br><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/4.png" alt=""></p>
<h2 id="Pregel的计算过程"><a href="#Pregel的计算过程" class="headerlink" title="Pregel的计算过程"></a>Pregel的计算过程</h2><p>•Pregel的计算过程是由一系列被称为“超步”的迭代组成的<br>•在每个超步中，每个顶点上面都会并行执行用户自定义的函数，该函数描述了一个顶点V在一个超步S中需要执行的操作<br>•该函数可以读取前一个超步(S-1)中其他顶点发送给顶点V的消息，执行相应计算后，修改顶点V及其出射边的状态，然后沿着顶点V的出射边发送消息给其他顶点，而且，一个消息可能经过多条边的传递后被发送到任意已知ID的目标顶点上去<br>•这些消息将会在下一个超步(S+1)中被目标顶点接收，然后象上述过程一样开始下一个超步(S+1)的迭代过程<br><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/5.png" alt=""><br>•在Pregel计算过程中，一个算法什么时候可以结束，是由所有顶点的状态决定的<br>•在第0个超步，所有顶点处于活跃状态<br>•当一个顶点不需要继续执行进一步的计算时，就会把自己的状态设置为“停机”，进入非活跃状态<br>•当一个处于非活跃状态的顶点收到来自其他顶点的消息时，Pregel计算框架必须根据条件判断来决定是否将其显式唤醒进入活跃状态<br>•当图中所有的顶点都已经标识其自身达到“非活跃（inactive）”状态，并且没有消息在传送的时候，算法就可以停止运行</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/7.png" alt=""></p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/8.png" alt=""></p>
<h1 id="Pregel的C-API"><a href="#Pregel的C-API" class="headerlink" title="Pregel的C++ API"></a>Pregel的C++ API</h1><p>Pregel已经预先定义好一个基类——Vertex类：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">template &lt;typename VertexValue, typename EdgeValue, typename MessageValue&gt;</div><div class="line">class Vertex &#123;</div><div class="line">  public:</div><div class="line">    virtual void Compute(MessageIterator* msgs) = 0;</div><div class="line">    const string&amp; vertex_id() const;</div><div class="line">    int64 superstep() const;</div><div class="line">    const VertexValue&amp; GetValue();</div><div class="line">    VertexValue* MutableValue();</div><div class="line">    OutEdgeIterator GetOutEdgeIterator(); </div><div class="line">    void SendMessageTo(const string&amp; dest_vertex,  const MessageValue&amp; message);</div><div class="line">    void VoteToHalt();</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>•在Vetex类中，定义了三个值类型参数，分别表示顶点、边和消息。每一个顶点都有一个给定类型的值与之对应<br>•编写Pregel程序时，需要继承Vertex类，并且覆写Vertex类的虚函数Compute()</p>
<h2 id="消息传递机制"><a href="#消息传递机制" class="headerlink" title="消息传递机制"></a>消息传递机制</h2><p>• 顶点之间的通讯是借助于消息传递机制来实现的，每条消息都包含了消息值和需要到达的目标顶点ID。用户可以通过Vertex类的模板参数来设定消息值的数据类型<br>• 在一个超步S中，一个顶点可以发送任意数量的消息，这些消息将在下一个超步（S+1）中被其他顶点接收<br>• 一个顶点V通过与之关联的出射边向外发送消息，并且，消息要到达的目标顶点并不一定是与顶点V相邻的顶点，一个消息可以连续经过多条连通的边到达某个与顶点V不相邻的顶点U，U可以从接收的消息中获取到与其不相邻的顶点V的ID</p>
<h2 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h2><p>• Pregel计算框架在消息发出去之前，Combiner可以将发往同一个顶点的多个整型值进行求和得到一个值，只需向外发送这个“求和结果”，从而实现了由多个消息合并成一个消息，大大减少了传输和缓存的开销<br>• 在默认情况下，Pregel计算框架并不会开启Combiner功能<br>• 当用户打算开启Combiner功能时，可以继承Combiner类并覆写虚函数Combine()<br>• 此外，通常只对那些满足交换律和结合律的操作才可以去开启Combiner功能</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/9.png" alt=""></p>
<h2 id="Aggregator"><a href="#Aggregator" class="headerlink" title="Aggregator"></a>Aggregator</h2><p>• Aggregator提供了一种全局通信、监控和数据查看的机制<br>• 在一个超步S中，每一个顶点都可以向一个Aggregator提供一个数据，Pregel计算框架会对这些值进行聚合操作产生一个值，在下一个超步（S+1）中，图中的所有顶点都可以看见这个值<br>• Aggregator的聚合功能，允许在整型和字符串类型上执行最大值、最小值、求和操作，比如，可以定义一个“Sum”Aggregator来统计每个顶点的出射边数量，最后相加可以得到整个图的边的数量<br>• Aggregator还可以实现全局协同的功能，比如，可以设计“and”Aggregator来决定在某个超步中Compute()函数是否执行某些逻辑分支，只有当“and” Aggregator显示所有顶点都满足了某条件时，才去执行这些逻辑分支</p>
<h2 id="拓扑改变"><a href="#拓扑改变" class="headerlink" title="拓扑改变"></a>拓扑改变</h2><p>• Pregel计算框架允许用户在自定义函数Compute()中定义操作，修改图的拓扑结构，比如在图中增加（或删除）边或顶点<br>• 对于全局拓扑改变，Pregel采用了惰性协调机制<br>• 对于本地的局部拓扑改变，是不会引发冲突的，顶点或边的本地增减能够立即生效，很大程度上简化了分布式编程</p>
<h2 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h2><p>• 在Pregel计算框架中，图的保存格式多种多样，包括文本文件、关系数据库或键值数据库等<br>• 在Pregel中，“从输入文件生成得到图结构”和“执行图计算”这两个过程是分离的，从而不会限制输入文件的格式<br>• 对于输出，Pregel也采用了灵活的方式，可以以多种方式进行输出</p>
<h1 id="Pregel的体系结构"><a href="#Pregel的体系结构" class="headerlink" title="Pregel的体系结构"></a>Pregel的体系结构</h1><h2 id="Pregel的执行过程"><a href="#Pregel的执行过程" class="headerlink" title="Pregel的执行过程"></a>Pregel的执行过程</h2><p>•在Pregel计算框架中，一个大型图会被划分成许多个分区，每个分区都包含了一部分顶点以及以其为起点的边<br>•一个顶点应该被分配到哪个分区上，是由一个函数决定的，系统默认函数为hash(ID) mod N，其中，N为所有分区总数，ID是这个顶点的标识符；当然，用户也可以自己定义这个函数<br>•这样，无论在哪台机器上，都可以简单根据顶点ID判断出该顶点属于哪个分区，即使该顶点可能已经不存在了</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/10.png" alt=""></p>
<p>在理想的情况下（不发生任何错误），一个Pregel用户程序的执行过<br>程如下：<br>（1）选择集群中的多台机器执行图计算任务，有一台机器会被选为Master，其他机器作为Worker<br>（2）Master把一个图分成多个分区，并把分区分配到多个Worker。一个Worker会领到一个或多个分区，每个Worker知道所有其他Worker所分配到的分区情况</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/11.png" alt=""></p>
<p>（3）Master会把用户输入划分成多个部分。然后，Master会为每个Worker分配用户输入的一部分。如果一个Worker从输入内容中加载到的顶点，刚好是自己所分配到的分区中的顶点，就会立即更新相应的数据结构。否则，该Worker会根据加载到的顶点的ID，把它发送到其所属的分区所在的Worker上。当所有的输入都被加载后，图中的所有顶点都会被标记为“活跃”状态。</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/12.png" alt=""></p>
<p>（4）Master向每个Worker发送指令，Worker收到指令后，开始运行一个超步。当一个超步中的所有工作都完成以后，Worker会通知Master，并把自己在下一个超步还处于“活跃”状态的顶点的数量报告给Master。上述步骤会被不断重复，直到所有顶点都不再活跃并且系统中不会有任何消息在传输，这时，执行过程才会结束。<br>（5）计算过程结束后，Master会给所有的Worker发送指令，通知每个Worker对自己的计算结果进行持久化存储</p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/13.png" alt=""></p>
<h2 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h2><p>• Pregel采用检查点机制来实现容错。在每个超步的开始，Master会通知所有的Worker把自己管辖的分区的状态写入到持久化存储设备<br>• Master会周期性地向每个Worker发送ping消息，Worker收到ping消息后会给Master发送反馈消息<br>• 每个Worker上都保存了一个或多个分区的状态信息，当一个Worker发生故障时，它所负责维护的分区的当前状态信息就会丢失。Master监测到一个Worker发生故障“失效”后，会把失效Worker所分配到的分区，重新分配到其他处于正常工作状态的Worker集合上，然后，所有这些分区会从最近的某超步S开始时写出的检查点中，重新加载状态信息</p>
<h2 id="Worker"><a href="#Worker" class="headerlink" title="Worker"></a>Worker</h2><p>在一个Worker中，它所管辖的分区的状态信息是保存在内存中的。<br>分区中的顶点的状态信息包括：<br>•顶点的当前值<br>•以该顶点为起点的出射边列表，每条出射边包含了目标顶点ID和边的值<br>•消息队列，包含了所有接收到的、发送给该顶点的消息<br>•标志位，用来标记顶点是否处于活跃状态<br>在每个超步中，Worker会对自己所管辖的分区中的每个顶点进行遍历，并调用顶点上的Compute()函数，在调用时，会把以下三个参数传递进去：<br>•该顶点的当前值<br>•一个接收到的消息的迭代器<br>•一个出射边的迭代器</p>
<p>•在Pregel中，为了获得更好的性能，“标志位”和输入消息队列是分开保存的<br>•对于每个顶点而言，Pregel只保存一份顶点值和边值，但是，会保存两份“标志位”和输入消息队列，分别用于当前超步和下一个超步<br>•如果一个顶点V在超步S接收到消息，那么，它表示V将会在下一个超步S+1中（而不是当前超步S中）处于“活跃”状态</p>
<p>•当一个Worker上的一个顶点V需要发送消息到其他顶点U时，该Worker会首先判断目标顶点U是否位于自己机器上<br>•如果目标顶点U在自己的机器上，就直接把消息放入到与目标顶点U对应的输入消息队列中<br>•如果发现目标顶点U在远程机器上，这个消息就会被暂时缓存到本地，当缓存中的消息数目达到一个事先设定的阈值时，这些缓存消息会被批量异步发送出去，传输到目标顶点所在的Worker上</p>
<h2 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h2><p>•Master主要负责协调各个Worker执行任务，每个Worker会借助于名称服务系统定位到Master的位置，并向Master发送自己的注册信息，Master会为每个Worker分配一个唯一的ID<br>•Master维护着关于当前处于“有效”状态的所有Worker的各种信息，包括每个Worker的ID和地址信息，以及每个Worker被分配到的分区信息<br>•Master中保存这些信息的数据结构的大小，只与分区的数量有关，而与顶点和边的数量无关</p>
<p>•一个大规模图计算任务会被Master分解到多个Worker去执行，在每个超步开始时，Master都会向所有处于“有效”状态的Worker发送相同的指令，然后等待这些Worker的回应<br>•如果在指定时间内收不到某个Worker的反馈，Master就认为这个Worker失效<br>•如果参与任务执行的多个Worker中的任意一个发生了故障失效，Master就会进入恢复模式<br>•在每个超步中，图计算的各种工作，比如输入、输出、计算、保存和从检查点中恢复，都会在“路障（barrier）”之前结束</p>
<p>•Master在内部运行了一个HTTP服务器来显示图计算过程的各种信息<br>•用户可以通过网页随时监控图计算执行过程各个细节<br>    •图的大小<br>    •关于出度分布的柱状图<br>    •处于活跃状态的顶点数量<br>    •在当前超步的时间信息和消息流量<br>    •所有用户自定义Aggregator的值</p>
<h2 id="Aggregator-1"><a href="#Aggregator-1" class="headerlink" title="Aggregator"></a>Aggregator</h2><p>• 每个用户自定义的Aggregator都会采用聚合函数对一个值集合进行聚合计算得到一个全局值<br>• 每个Worker都保存了一个Aggregator的实例集，其中的每个实例都是由类型名称和实例名称来标识的<br>• 在执行图计算过程的某个超步S中，每个Worker会利用一个Aggregator对当前本地分区中包含的所有顶点的值进行归约，得到一个本地的局部归约值<br>• 在超步S结束时，所有Worker会将所有包含局部归约值的Aggregator的值进行最后的汇总，得到全局值，然后提交给Master<br>• 在下一个超步S+1开始时，Master就会将Aggregator的全局值发送给每个Worker</p>
<h1 id="Pregel的应用实例——单源最短路径"><a href="#Pregel的应用实例——单源最短路径" class="headerlink" title="Pregel的应用实例——单源最短路径"></a>Pregel的应用实例——单源最短路径</h1><p>Dijkstra算法是解决单源最短路径问题的贪婪算法</p>
<p>Pregel非常适合用来解决单源最短路径问题，实现代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">class ShortestPathVertex</div><div class="line">  : public Vertex&lt;int, int, int&gt; &#123;</div><div class="line">    void Compute(MessageIterator* msgs) &#123;</div><div class="line">    int mindist = IsSource(vertex_id()) ? 0 : INF;</div><div class="line">    for (; !msgs-&gt;Done(); msgs-&gt;Next())</div><div class="line">    mindist = min(mindist, msgs-&gt;Value());</div><div class="line">    if (mindist &lt; GetValue()) &#123;</div><div class="line">    *MutableValue() = mindist;</div><div class="line">    OutEdgeIterator iter = GetOutEdgeIterator();</div><div class="line">    for (; !iter.Done(); iter.Next())</div><div class="line">    SendMessageTo(iter.Target(),</div><div class="line">    mindist + iter.GetValue());</div><div class="line">    &#125;</div><div class="line">    VoteToHalt();</div><div class="line">  &#125;</div><div class="line"> &#125;;</div></pre></td></tr></table></figure></p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/14.png" alt=""></p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/15.png" alt=""></p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/16.png" alt=""></p>
<p><img src="/2018/05/28/大数据基础学习笔记（十）——图计算/17.png" alt=""><br>超步1：<br>•顶点0：没有收到消息，依然非活跃<br>•顶点1：收到消息100（唯一消息），被显式唤醒，执行计算，mindist变为100，小于顶点值INF，顶点值修改为100，没有出射边，不需要发送消息，最后变为非活跃<br>•顶点2：收到消息30，被显式唤醒，执行计算，mindist变为30，小于顶点值ZNF，顶点值修改为30，有两条出射边，向顶点3发送消息90（即：30+60），向顶点1发送消息90（即：30+60），最后变为非活跃<br>•顶点3：没有收到消息，依然非活跃<br>•顶点4：收到消息10，被显式唤醒，执行计算，mindist变为10，小于顶点值INF，顶点值修改为10，向顶点3发送消息60（即：10+50），最后变为非活跃剩余超步省略……<br>当所有顶点非活跃，并且没有消息传递，就结束</p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（九）——流计算]]></title>
      <url>/2018/05/22/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89%E2%80%94%E2%80%94%E6%B5%81%E8%AE%A1%E7%AE%97/</url>
      <content type="html"><![CDATA[<h1 id="什么是流数据"><a href="#什么是流数据" class="headerlink" title="什么是流数据"></a>什么是流数据</h1><p>• 近年来，在Web应用、网络监控、传感监测等领域，兴起了一种新的数据密集型应用——流数据，即数据以大量、快速、时变的流形式持续到达<br>• 实例：PM2.5检测、电子商务网站用户点击流<br>• 流数据具有如下特征：<br>– 数据快速持续到达，潜在大小也许是无穷无尽的<br>– 数据来源众多，格式复杂<br>– 数据量大，但是不十分关注存储，一旦经过处理，要么被丢弃，要么被归档存储<br>– 注重数据的整体价值，不过分关注个别数据<br>– 数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序<br>• 对静态数据和流数据的处理，对应着两种截然不同的计算模式：批量计算和实时计算<br>•批量计算：充裕时间处理静态数据，如Hadoop<br>•流数据不适合采用批量计算，因为流数据不适合用传统的关系模型建模<br>•流数据必须采用实时计算，响应时间为秒级<br>•在大数据时代，数据格式复杂、来源众多、数据量巨大，对实时计算提出了很大的挑战。因此，针对流数据的实时计算——流计算，应运而生</p>
<h1 id="流计算的概念"><a href="#流计算的概念" class="headerlink" title="流计算的概念"></a>流计算的概念</h1><p>• 流计算秉承一个基本理念，即 数据的价值随着时间的流逝而降低，如用户点击流。因此，当事件出现时就应该立即进行处理，而不是缓存起来进行批量处理。为了及时处理流数据，就需要一个低延迟、可扩展、高可靠的处理引擎<br>• 对于一个流计算系统来说，它应达到如下需求：<br>– 高性能<br>– 海量式<br>– 实时性<br>– 分布式<br>– 易用性<br>– 可靠性</p>
<h1 id="流计算与Hadoop"><a href="#流计算与Hadoop" class="headerlink" title="流计算与Hadoop"></a>流计算与Hadoop</h1><p>• Hadoop设计的初衷是面向大规模数据的批量处理<br>• MapReduce是专门面向静态数据的批量处理的，内部各种实现机制都为批处理做了高度优化，不适合用于处理持续到达的动态数据• 可能会想到一种“变通”的方案来降低批处理的时间延迟——将基于MapReduce的批量处理转为小批量处理，将输入数据切成小的片段，每隔一个周期就启动一次MapReduce作业。但这种方式也无法有效处理流数据<br>– 切分成小片段，可以降低延迟，但是也增加了附加开销，还要处理片段之间依赖关系<br>– 需要改造MapReduce以支持流式处理<br>结论：鱼和熊掌不可兼得，Hadoop擅长批处理，但是不适合流计算<br>• 当前业界诞生了许多专门的流数据实时计算系统来满足各自需求：<br>• 商业级：IBM InfoSphere Streams和IBM StreamBase<br>• 开源流计算框架：<br>– Twitter Storm：免费、开源的分布式实时计算系统，可简单、高效、可靠地处理大量的流数据<br>– Yahoo! S4（Simple Scalable Streaming System）：开源流计算平台，是通用的、分布式的、可扩展的、分区容错的、可插拔的流式系统<br>• 公司为支持自身业务开发的流计算框架：<br>– Facebook Puma<br>– Dstream（百度）<br>– 银河流数据处理平台（淘宝）</p>
<h1 id="流计算处理流程"><a href="#流计算处理流程" class="headerlink" title="流计算处理流程"></a>流计算处理流程</h1><p>• 传统的数据处理流程，需要先采集数据并存储在关系数据库等数据管理系统中，之后由用户通过查询操作和数据管理系统进行交互<br>• 传统的数据处理流程隐含了两个前提：<br>–  存储的数据是旧的。存储的静态数据是过去某一时刻的快照，这些数据在查询时可能已不具备时效性了<br>–  需要用户主动发出查询</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/1.png" alt="传统的数据处理流程"></p>
<p>• 流计算的处理流程一般包含三个阶段：数据实时采集、数据实时计算、实时查询服务</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/2.png" alt="流计算处理流程示意图"></p>
<h2 id="数据实时采集"><a href="#数据实时采集" class="headerlink" title="数据实时采集"></a>数据实时采集</h2><p>• 数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟与稳定可靠<br>• 以日志数据为例，由于分布式集群的广泛应用，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据<br>• 目前有许多互联网公司发布的开源分布式日志采集系统均可满足每秒数百MB的数据采集和传输需求，如：</p>
<p>– <code>Facebook的Scribe</code></p>
<p>– <code>LinkedIn的Kafka</code></p>
<p>– <code>淘宝的Time Tunnel</code></p>
<p>– <code>基于Hadoop的Chukwa和Flume</code></p>
<p>• 数据采集系统的基本架构一般有以下三个部分：<br>– Agent：主动采集数据，并把数据推送到Collector部分<br>– Collector：接收多个Agent的数据，并实现有序、可靠、高性能的转发<br>– Store：存储Collector转发过来的数据（对于流计算不存储数据）</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/3.png" alt="数据采集系统基本架构"></p>
<h2 id="数据实时计算"><a href="#数据实时计算" class="headerlink" title="数据实时计算"></a>数据实时计算</h2><p>• 数据实时计算阶段对采集的数据进行实时的分析和计算，并反馈实时结果<br>• 经流处理系统处理后的数据，可视情况进行存储，以便之后再进行分析计算。在时效性要求较高的场景中，处理之后的数据也可以直接丢弃</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/4.png" alt="数据实时计算流程"></p>
<h2 id="实时查询服务"><a href="#实时查询服务" class="headerlink" title="实时查询服务"></a>实时查询服务</h2><p>• 实时查询服务：经由流计算框架得出的结果可供用户进行实时查询、展示或储存<br>• 传统的数据处理流程，用户需要主动发出查询才能获得想要的结果。而在流处理流程中，实时查询服务可以不断更新结果，并将用户所需的结果实时推送给用户<br>• 虽然通过对传统的数据处理系统进行定时查询，也可以实现不断地更新结果和结果推送，但通过这样的方式获取的结果，仍然是根据过去某一时刻的数据得到的结果，与实时结果有着本质的区别<br>• 可见，流处理系统与传统的数据处理系统有如下不同：<br>– 流处理系统处理的是实时的数据，而传统的数据处理系统处理的是预先存储好的静态数据<br>– 用户通过流处理系统获取的是实时结果，而通过传统的数据处理系统，获取的是过去某一时刻的结果<br>– 流处理系统无需用户主动发出查询，实时查询服务可以主动将实时结果推送给用户</p>
<h1 id="开源流计算框架Storm"><a href="#开源流计算框架Storm" class="headerlink" title="开源流计算框架Storm"></a>开源流计算框架Storm</h1><p>• Twitter Storm是一个免费、开源的分布式实时计算系统，Storm对于实时计算的意义类似于Hadoop对于批处理的意义，Storm可以简单、高效、可靠地处理流数据，并支持多种编程语言</p>
<p>• Storm框架可以方便地与数据库系统进行整合，从而开发出强大的实时计算系统</p>
<p>• Twitter是全球访问量最大的社交网站之一，Twitter开发Storm流处理框架也是为了应对其不断增长的流数据实时处理需求</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/5.png" alt=""></p>
<h2 id="Storm的特点"><a href="#Storm的特点" class="headerlink" title="Storm的特点"></a>Storm的特点</h2><p>• Storm可用于许多领域中，如实时分析、在线机器学习、持续计算、远程RPC、数据提取加载转换等</p>
<p>• Storm具有以下主要特点：<br>– 整合性<br>– 简易的API<br>– 可扩展性<br>– 可靠的消息处理<br>– 支持各种编程语言<br>– 快速部署<br>– 免费、开源</p>
<h2 id="Storm设计思想"><a href="#Storm设计思想" class="headerlink" title="Storm设计思想"></a>Storm设计思想</h2><p>• Storm主要术语包括Streams、Spouts、Bolts、Topology和Stream Groupings</p>
<p>• <code>Streams</code> ：Storm将流数据Stream描述成一个无限的Tuple序列，这些Tuple序列会以分布式的方式并行地创建和处理</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/6.png" alt=""></p>
<p>•每个tuple是一堆值，每个值有一个名字，并且每个值可以是任何类型<br>•Tuple本来应该是一个Key-Value的Map，由于各个组件间传递的tuple的字段名称已经事先定义好了，所以Tuple只需要按序填入各个Value，所以就是一个Value List（值列表）</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/7.png" alt=""></p>
<p>• <code>Spout</code>：Storm认为每个Stream都有一个源头，并把这个源头抽象为Spout</p>
<p>• 通常Spout会从外部数据源（队列、数据库等）读取数据，然后封装成Tuple形式，发送到Stream中。Spout是一个主动的角色，在接口内部有个nextTuple函，Storm框架会不停的调用该函数</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/8.png" alt=""></p>
<p>• <code>Bolt</code> ：Storm将Streams的状态转换过程抽象为Bolt。Bolt即可以处理Tuple，也可以将处理后的Tuple作为新的Streams发送给其他Bolt</p>
<p>• Bolt可以执行过滤、函数操作、Join、操作数据库等任何操作<br>• Bolt是一个被动的角色，其接口中有一个execute(Tuple input)方法，在接收到消息之后会调用此函数，用户可以在此方法中执行自己的处理逻辑</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/9.png" alt=""></p>
<p>• <code>Topology</code> ：Storm将Spouts和Bolts组成的网络抽象成Topology，它可以被提交到Storm集群执行。Topology可视为流转换图，图中节点是一个Spout或<br>Bolt，边则表示Bolt订阅了哪个Stream。当Spout或者Bolt发送元组时，它会把元组发送到每个订阅了该Stream的Bolt上进行处理<br>• Topology里面的每个处理组件（Spout或Bolt）都包含处理逻辑， 而组件之间的连接则表示数据流动的方向<br>• Topology里面的每一个组件都是并行运行的<br>•在Topology里面可以指定每个组件的并行度，Storm会在集群里面分配那么多的线程来同时计算<br>•在Topology的具体实现上，Storm中的Topology定义仅仅是一些Thrift结构体（二进制高性能的通信中间件），支持各种编程语言进行定义</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/10.png" alt=""></p>
<p>• <code>Stream Groupings</code> ：Storm中的Stream Groupings用于告知Topology如何在两个组件间（如Spout和Bolt之间，或者不同的Bolt之间）进行Tuple的传送。每一个Spout和Bolt都可以有多个分布式任务，一个任务在什么时候、以什么方式发送Tuple就是由Stream Groupings来决定的</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/11.png" alt=""></p>
<p>目前，Storm中的Stream Groupings有如下几种方式：</p>
<p>(1)ShuffleGrouping：随机分组，随机分发Stream中的Tuple，保证每个Bolt的Task接收Tuple数量大致一致<br>(2)FieldsGrouping：按照字段分组，保证相同字段的Tuple分配到同一个Task中<br>(3)AllGrouping：广播发送，每一个Task都会收到所有的Tuple<br>(4)GlobalGrouping：全局分组，所有的Tuple都发送到同一个Task中<br>(5)NonGrouping：不分组，和ShuffleGrouping类似，当前Task的执行会和它的被订阅者在同一个线程中执行<br>(6)DirectGrouping：直接分组，直接指定由某个Task来执行Tuple的处理</p>
<h2 id="Storm框架设计"><a href="#Storm框架设计" class="headerlink" title="Storm框架设计"></a>Storm框架设计</h2><p>•Storm运行任务的方式与Hadoop类似：Hadoop运行的是MapReduce作业，而Storm运行的是“Topology”<br>•但两者的任务大不相同，主要的不同是：MapReduce作业最终会完成计算并结束运行，而Topology将持续处理消息（直到人为终止）</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/12.png" alt=""></p>
<p>• Storm集群采用“Master—Worker”的节点方式：<br>– Master节点运行名为“Nimbus”的后台程序（类似Hadoop中的“JobTracker”），负责在集群范围内分发代码、为Worker分配任务和监测故障<br>– Worker节点运行名为“Supervisor”的后台程序，负责监听分配给它所在机器的工作，即根据Nimbus分配的任务来决定启动或停止Worker进程，一个Worker节点上同时运行若干个Worker进程<br>• Storm使用Zookeeper来作为分布式协调组件，负责Nimbus和多个Supervisor之间的所有协调工作。借助于Zookeeper，若Nimbus进程或Supervisor进程意外终止，重启时也能读取、恢复之前的状态并继续工作，使得Storm极其稳定</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/13.png" alt="Storm集群架构示意图"></p>
<p><code>worker进程</code></p>
<p>(1)Worker进程:每个worker进程都属于一个特定的Topology，每个Supervisor节点的worker可以有多个，每个worker对Topology中的每个组件（Spout或Bolt）运行一个或者多个executor线程来提供task的运行服务<br>(2)Executor：executor是产生于worker进程内部的线程，会执行同一个组件的一个或者多个task。<br>(3)Task:实际的数据处理由task完成Worker、Executor和Task的关系</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/14.png" alt="Worker、Executor和Task的关系"></p>
<p>• 基于这样的架构设计，Storm的工作流程如下图所示：<br>•所有Topology任务的提交必须在Storm客户端节点上进行，提交后，由Nimbus节点分配给其他Supervisor节点进行处理<br>•Nimbus节点首先将提交的Topology进行分片，分成一个个Task，分配给相应的Supervisor，并将Task和Supervisor相关的信息提交到Zookeeper集群上<br>•Supervisor会去Zookeeper集群上认领自己的Task，通知自己的Worker进程进行Task的处理</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/15.png" alt="Storm工作流程示意图"></p>
<h1 id="Spark-Streaming"><a href="#Spark-Streaming" class="headerlink" title="Spark Streaming"></a>Spark Streaming</h1><h2 id="Spark-Streaming设计"><a href="#Spark-Streaming设计" class="headerlink" title="Spark Streaming设计"></a>Spark Streaming设计</h2><p>•Spark Streaming可整合多种输入数据源，如Kafka、Flume、HDFS，甚至是普通的TCP套接字。经处理后的数据可存储至文件系统、数据库，或显示在仪表盘里</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/16.png" alt="Spark Streaming支持的输入、输出数据源"></p>
<p>Spark Streaming的基本原理是将实时输入数据流以时间片（秒级）为单位进行拆分，然后经Spark引擎以类似批处理的方式处理每个时间片数据</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/17.png" alt="Spark Streaming执行流程"></p>
<p>Spark Streaming最主要的抽象是DStream（Discretized Stream，离散化数据流），表示连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（如1秒）分成一段一段的DStream，每一段数据转换为Spark中的RDD，并且对DStream的操作都最终转变为对相应的RDD的操作</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/18.png" alt="DStream操作示意图"></p>
<h2 id="Spark-Streaming与Storm的对比"><a href="#Spark-Streaming与Storm的对比" class="headerlink" title="Spark Streaming与Storm的对比"></a>Spark Streaming与Storm的对比</h2><p>•Spark Streaming和Storm最大的区别在于，Spark Streaming无法实现毫秒级的流计算，而Storm可以实现毫秒级响应</p>
<p>•Spark Streaming构建在Spark上，一方面是因为Spark的低延迟执行引擎（100ms+）可以用于实时计算，另一方面，相比于Storm，RDD数据集更容易做高效的容错处理</p>
<p>•Spark Streaming采用的小批量处理的方式使得它可以同时兼容批量和实时数据处理的逻辑和算法，因此，方便了一些需要历史数据和实时数据联合分析的特定应用场合</p>
<h1 id="Samza"><a href="#Samza" class="headerlink" title="Samza"></a>Samza</h1><p>1.作业</p>
<p>一个作业（Job）是对一组输入流进行处理转化成输出流的程序。</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/19.png" alt=""></p>
<p>2.分区</p>
<p>•Samza的流数据单位既不是Storm中的元组，也不是Spark Streaming中的DStream，而是一条条消息<br>•Samza中的每个流都被分割成一个或多个分区，对于流里的每一个分区而言，都是一个有序的消息序列，后续到达的消息会根据一定规则被追加到其中一个分区里</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/20.png" alt=""></p>
<p>3.任务</p>
<p>•一个作业会被进一步分割成多个任务（Task）来执行，其中，每个任务负责处理作业中的一个分区<br>•分区之间没有定义顺序，从而允许每一个任务独立执行<br>•YARN调度器负责把任务分发给各个机器，最终，一个工作中的多个任务会被分发到多个机器进行分布式并行处理</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/21.png" alt=""></p>
<p>4.数据流图</p>
<p>•一个数据流图是由多个作业构成的，其中，图中的每个节点表示包含数据的流，每条边表示数据传输<br>•多个作业串联起来就完成了流式的数据处理流程<br>•由于采用了异步的消息订阅分发机制，不同任务之间可以独立运行</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/22.png" alt=""></p>
<h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>•Samza系统架构主要包括<br>•流数据层（Kafka）<br>•执行层（YARN）<br>•处理层（Samza API）<br>•流处理层和执行层都被设计成可插拔的，开发人员可以使用其他框架来替代YARN和Kafka</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/24.png" alt=""></p>
<p>处理分析过程如下：</p>
<p>•Samza客户端需要执行一个Samza作业时，它会向YARN的ResouceManager提交作业请求</p>
<p>•ResouceManager通过与NodeManager沟通为该作业分配容器（包含了CPU、内存等资源）来运行Samza ApplicationMaster</p>
<p>•Samza ApplicationMaster进一步向ResourceManager申请运行任务的容器</p>
<p>•获得容器后，Samza ApplicationMaster与容器所在的NodeManager沟通，启动该容器，并在其中运行Samza Task Runner</p>
<p>•Samza Task Runner负责执行具体的Samza任务，完成流数据处理分析</p>
<p><img src="/2018/05/22/大数据基础学习笔记（九）——流计算/25.png" alt=""></p>
<h1 id="Storm、Spark-Streaming和Samza的应用场景"><a href="#Storm、Spark-Streaming和Samza的应用场景" class="headerlink" title="Storm、Spark Streaming和Samza的应用场景"></a>Storm、Spark Streaming和Samza的应用场景</h1><p>•从编程的灵活性来讲，Storm是比较理想的选择，它使用Apache Thrift，可以用任何编程语言来编写拓扑结构（Topology）</p>
<p>•当需要在一个集群中把流计算和图计算、机器学习、SQL查询分析等进行结合时，可以选择Spark Streaming，因为，在Spark上可以统一部署Spark SQL，Spark Streaming、MLlib，GraphX等组件，提供便捷的一体化编程模型</p>
<p>•当有大量的状态需要处理时，比如每个分区都有数十亿个元组，则可以选择Samza。当应用场景需要毫秒级响应时，可以选择Storm和Samza，因为Spark Streaming无法实现毫秒级的流计算</p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（八）——Spark]]></title>
      <url>/2018/05/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%E2%80%94%E2%80%94Spark/</url>
      <content type="html"><![CDATA[<h1 id="Spark的特点"><a href="#Spark的特点" class="headerlink" title="Spark的特点"></a>Spark的特点</h1><p>•运行速度快：使用DAG执行引擎以支持循环数据流与内存计算</p>
<p>•容易使用：支持使用Scala、Java、Python和R语言进行编程，可以通过Spark Shell进行交互式编程</p>
<p>•通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件</p>
<p>•运行模式多样：可运行于独立的集群模式中，可运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源</p>
<h1 id="Scala简介"><a href="#Scala简介" class="headerlink" title="Scala简介"></a>Scala简介</h1><p>Scala是一门现代的多范式编程语言，运行于Java平台（JVM，Java 虚拟机），并兼容现有的Java程序</p>
<p>Scala的特性：</p>
<p>•Scala具备强大的并发性，支持函数式编程，可以更好地支持分布式系统</p>
<p>•Scala语法简洁，能提供优雅的API</p>
<p>Scala兼容Java，运行速度快，且能融合到Hadoop生态圈中</p>
<p>Scala是Spark的主要编程语言，但Spark还支持Java、Python、R作为编程语言</p>
<p>Scala的优势是提供了REPL（Read-Eval-Print Loop，交互式解释器），提高程序开发效率</p>
<h1 id="Spark与Hadoop的对比"><a href="#Spark与Hadoop的对比" class="headerlink" title="Spark与Hadoop的对比"></a>Spark与Hadoop的对比</h1><p>Hadoop存在如下一些缺点：</p>
<p>•表达能力有限</p>
<p>•磁盘IO开销大</p>
<p>•延迟高</p>
<p>•任务之间的衔接涉及IO开销</p>
<p>•在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段的计算任务</p>
<p>Spark在借鉴Hadoop MapReduce优点的同时，很好地解决了MapReduce所面临的问题</p>
<p>相比于Hadoop MapReduce，Spark主要具有如下优点：</p>
<p>•Spark的计算模式也属于MapReduce，但不局限于Map和Reduce操作，还提供了多种数据集操作类型，编程模型比Hadoop MapReduce更灵活</p>
<p>•Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率<br>更高</p>
<p>Spark基于DAG的任务调度执行机制，要优于Hadoop MapReduce的迭代执行机制</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/1.png" alt="Hadoop与Spark的执行流程对比"></p>
<p>•使用Hadoop进行迭代计算非常耗资源</p>
<p>•Spark将数据载入内存后，之后的迭代计算都可以直接使用内存中的中间结果作运算，避免了从磁盘中频繁读取数据</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/2.png" alt="Hadoop与Spark执行逻辑回归的时间对比"></p>
<h1 id="Spark生态系统"><a href="#Spark生态系统" class="headerlink" title="Spark生态系统"></a>Spark生态系统</h1><p>在实际应用中，大数据处理主要包括以下三个类型：</p>
<p>•复杂的批量数据处理：通常时间跨度在数十分钟到数小时之间</p>
<p>•基于历史数据的交互式查询：通常时间跨度在数十秒到数分钟之间</p>
<p>•基于实时数据流的数据处理：通常时间跨度在数百毫秒到数秒之间</p>
<p>当同时存在以上三种场景时，就需要同时部署三种不同的软件</p>
<p>•比如: MapReduce / Impala / Storm这样做难免会带来一些问题：</p>
<p>•不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换</p>
<p>•不同的软件需要不同的开发和维护团队，带来了较高的使用成本</p>
<p>•比较难以对同一个集群中的各个系统进行统一的资源协调和分配</p>
<p>•Spark的设计遵循“一个软件栈满足不同应用场景”的理念，逐渐形成了一套完整的生态系统</p>
<p>•既能够提供内存计算框架，也可以支持SQL即席查询、实时流式计算、机器学习和图计算等</p>
<p>•Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案</p>
<p>•因此，Spark所提供的生态系统足以应对上述三种场景，即同时支持批处理、交互式查询和流数据处理</p>
<p>Spark生态系统已经成为伯克利数据分析软件栈BDAS（Berkeley Data Analytics Stack）的重要组成部分</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/3.png" alt="BDAS架构"></p>
<p>Spark的生态系统主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/4.png" alt="Spark生态系统组件的应用场景"></p>
<h1 id="Spark运行架构"><a href="#Spark运行架构" class="headerlink" title="Spark运行架构"></a>Spark运行架构</h1><p>•RDD：是Resillient Distributed Dataset（弹性分布式数据集）的简称，是分布式内存的一个抽象概念，提供了一种高度受限的共享内存模型</p>
<p>•DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系</p>
<p>•Executor：是运行在工作节点（WorkerNode）的一个进程，负责运行Task</p>
<p>•Application：用户编写的Spark应用程序</p>
<p>•Task：运行在Executor上的工作单元</p>
<p>•Job：一个Job包含多个RDD及作用于相应RDD上的各种操作</p>
<p>•Stage：是Job的基本调度单位，一个Job会分为多组Task，每组Task被称为Stage，或者也被称为TaskSet，代表了一组关联的、相互之间没有Shuffle依<br>赖关系的任务组成的任务集</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/5.png" alt="基本概念"></p>
<p>•Spark运行架构包括集群资源管理器（Cluster Manager）、运行作业任务的工作节点（Worker Node）、每个应用的任务控制节点（Driver）和每个工作节点上负责具体任务的执行进程（Executor）</p>
<p>•资源管理器可以自带或Mesos或YARN</p>
<p>与Hadoop MapReduce计算框架相比，Spark所采用的Executor有两个优点：</p>
<p>•一是利用多线程来执行具体的任务，减少任务的启动开销</p>
<p>•二是Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，有效减少IO开销</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/6.png" alt="Spark运行架构"></p>
<p>•一个Application由一个Driver和若干个Job构成，一个Job由多个Stage构成，一个Stage由多个没有Shuffle关系的Task组成</p>
<p>•当执行一个Application时，Driver会向集群管理器申请资源，启动xecutor，并向Executor发送应用程序代码和文件，然后在Executor上执行Task，运行结束后，执行结果会返回给Driver，或者写到HDFS或者其他数据库中</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/7.png" alt="Spark中各种概念之间的相互关系"></p>
<h1 id="Spark运行基本流程"><a href="#Spark运行基本流程" class="headerlink" title="Spark运行基本流程"></a>Spark运行基本流程</h1><p>（1）首先为应用构建起基本的运行环境，即由Driver创建一个SparkContext，进行资源的申请、任务的分配和监控</p>
<p>（2）资源管理器为Executor分配资源，并启动Executor进程</p>
<p>（3）SparkContext根据RDD的依赖关系构建DAG图，DAG图提交给DAGScheduler解析成Stage，然后把一个个TaskSet提交给底层调度器TaskScheduler处理；Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行，并提供应用程序代码</p>
<p>（4）Task在Executor上运行，把执行结果反馈给TaskScheduler，然后反馈给<br>DAGScheduler，运行完毕后写入数据并释放所有资源</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/8.png" alt="Spark运行基本流程图"></p>
<p>总体而言，Spark运行架构具有以下特点：</p>
<p>（1）每个Application都有自己专属的Executor进程，并且该进程在Application运行期间一直驻留。Executor进程以多线程的方式运行Task</p>
<p>（2）Spark运行过程与资源管理器无关，只要能够获取Executor进程并保持通信即可</p>
<p>（3）Task采用了数据本地性和推测执行等优化机制</p>
<h1 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h1><p>1.设计背景</p>
<p>•许多迭代式算法（比如机器学习、图算法等）和交互式数据挖掘工具，共同之处是，不同计算阶段之间会重用中间结果</p>
<p>•目前的MapReduce框架都是把中间结果写入到HDFS中，带来了大量的数据复制、磁盘IO和序列化开销</p>
<p>•RDD就是为了满足这种需求而出现的，它提供了一个抽象的数据架构，我们不必担心底层数据的分布式特性，只需将具体的应用逻辑表达为一系列转换处理，不同RDD之间的转换操作形成依赖关系，可以实现管道化，避免中间数据存储</p>
<p>2.RDD 概念</p>
<p>•一个RDD就是一个分布式对象集合，本质上是一个只读的分区记录集合，每个RDD可分成多个分区，每个分区就是一个数据集片段，并且一个RDD的不同分区可以被保存到集群中不同的节点上，从而可以在集群中的不同节点上进行并行计算</p>
<p>•RDD提供了一种高度受限的共享内存模型，即RDD是只读的记录分区的集合，不能直接修改，只能基于稳定的物理存储中的数据集创建RDD，或者通过在其他RDD上执行确定的转换操作（如map、join和group by）而创建得到新的RDD</p>
<p>•RDD提供了一组丰富的操作以支持常见的数据运算，分为“动作”（Action）和“转换”（Transformation）两种类型</p>
<p>•RDD提供的转换接口都非常简单，都是类似map、filter、groupBy、join等粗粒度的数据转换操作，而不是针对某个数据项的细粒度修改（不适合网页爬虫）</p>
<p>•表面上RDD的功能很受限、不够强大，实际上RDD已经被实践证明可以高效地表达许多框架的编程模型（比如MapReduce、SQL、Pregel）</p>
<p>•Spark用Scala语言实现了RDD的API，程序员可以通过调用API实现对RDD的各种操作</p>
<p>RDD典型的执行过程如下：</p>
<p>•RDD读入外部数据源进行创建</p>
<p>•RDD经过一系列的转换（Transformation）操作，每一次都会产生不同的RDD，供给下一个转换操作使用</p>
<p>•最后一个RDD经过“动作”操作进行转换，并输出到外部数据源这一系列处理称为一个Lineage（血缘关系），即DAG拓扑排序的结果</p>
<p>优点：惰性调用、管道化、避免同步等待、不需要保存中间结果、每次操作变得简单</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/9.png" alt="Spark运行基本流程图"></p>
<p>3.RDD特性</p>
<p>Spark采用RDD以后能够实现高效计算的原因主要在于：</p>
<p>（1）高效的容错性</p>
<p>•现有容错机制：数据复制或者记录日志</p>
<p>•RDD：血缘关系、重新计算丢失分区、无需回滚系统、重算过程在不同节点之间并行、只记录粗粒度的操作</p>
<p>（2）中间结果持久化到内存，数据在内存中的多个RDD操作之间进行传递，避免了不必要的读写磁盘开销</p>
<p>（3）存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化</p>
<p>4.RDD之间的依赖关系</p>
<p>窄依赖表现为一个父RDD的分区对应于一个子RDD的分区或多个父RDD的分区对应于一个子RDD的分区</p>
<p>•宽依赖则表现为存在一个父RDD的一个分区对应一个子RDD的多个分区</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/10.png" alt="窄依赖与宽依赖的区别"></p>
<p>5.Stage的划分</p>
<p>Spark通过分析各个RDD的依赖关系生成了DAG，再通过分析各个RDD中的分区之间的依赖关系来决定如何划分Stage，具体划分方法是：</p>
<p>•在DAG中进行反向解析，遇到宽依赖就断开</p>
<p>•遇到窄依赖就把当前的RDD加入到Stage中</p>
<p>•将窄依赖尽量划分在同一个Stage中，可以实现流水线计算被分成三个Stage，在Stage2中，从map到union都是窄依赖，这两步操作可以形成一个流水线操作</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/11.png" alt="根据RDD分区的依赖关系划分Stage"><br>流水线操作实例分区7通过map操作生成的分区9，可以不用等待分区8到分区10这个map操作的计算结束，而是继续进行union操作，得到分区13，这样流水线执行大大提高了计算的效率</p>
<p>Stage的类型包括两种：ShuffleMapStage和ResultStage，具体如下：</p>
<p>（1）ShuffleMapStage：不是最终的Stage，在它之后还有其他Stage，所以，它的输出一定需要经过Shuffle过程，并作为后续Stage的输入；这种Stage是以Shuffle为输出边界，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出，其输出可以是另一个Stage的开始；在一个Job里可能有该类型的Stage，也可能没有该类型Stage；</p>
<p>（2）ResultStage：最终的Stage，没有输出，而是直接产生结果或存储。这种Stage是直接输出结果，其输入边界可以是从外部获取数据，也可以是另一个ShuffleMapStage的输出。在一个Job里必定有该类型Stage。<br>因此，一个Job含有一个或多个Stage，其中至少含有一个ResultStage。</p>
<p>6.RDD运行过程</p>
<p>通过上述对RDD概念、依赖关系和Stage划分的介绍，结合之前介绍的Spark运行<br>基本流程，再总结一下RDD在Spark架构中的运行过程：</p>
<p>（1）创建RDD对象；</p>
<p>（2）SparkContext负责计算RDD之间的依赖关系，构建DAG；</p>
<p>（3）DAGScheduler负责把DAG图分解成多个Stage，每个Stage中包含了多个<br>Task，每个Task会被TaskScheduler分发给各个WorkerNode上的Executor去执<br>行。<br><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/12.png" alt="RDD在Spark中的运行过程"></p>
<h1 id="Spark-SQL设计"><a href="#Spark-SQL设计" class="headerlink" title="Spark SQL设计"></a>Spark SQL设计</h1><p>Spark SQL在Hive兼容层面仅依赖HiveQL解析、Hive元数据，也就是说，从HQL被解析成抽象语法树（AST）起，就全部由Spark SQL接管了。Spark SQL执行计划生成和优化都由Catalyst（函数式关系查询优化框架）负责</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/13.png" alt="Spark SQL架构"></p>
<p>•Spark SQL增加了SchemaRDD（即带有Schema信息的RDD），使用户可以在Spark SQL中执行SQL语句，数据既可以来自RDD，也可以是Hive、HDFS、Cassandra等外部数据源，还可以是JSON格式的数据</p>
<p>•Spark SQL目前支持Scala、Java、Python三种语言，支持SQL-92规范</p>
<p><img src="/2018/05/17/大数据基础学习笔记（八）——Spark/14.png" alt="Spark SQL支持的数据格式和编程语言"></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（七）——数据仓库Hive]]></title>
      <url>/2018/05/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%E2%80%94%E2%80%94%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93Hive/</url>
      <content type="html"><![CDATA[<h1 id="数据仓库概念"><a href="#数据仓库概念" class="headerlink" title="数据仓库概念"></a>数据仓库概念</h1><p>数据仓库（Data Warehouse）是一个面向主题的（Subject Oriented）、集成<br>的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化（Time Variant）的数据集合，用于支持管理决策。</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/1.png" alt="数据仓库的体系结构"></p>
<h1 id="Hive简介"><a href="#Hive简介" class="headerlink" title="Hive简介"></a>Hive简介</h1><p>•Hive是一个构建于Hadoop顶层的数据仓库工具</p>
<p>•支持大规模数据存储、分析，具有良好的可扩展性</p>
<p>•某种程度上可以看作是用户编程接口，本身不存储和处理数据</p>
<p>•依赖分布式文件系统HDFS存储数据</p>
<p>•依赖分布式并行计算模型MapReduce处理数据</p>
<p>•定义了简单的类似SQL 的查询语言——HiveQL</p>
<p>•用户可以通过编写的HiveQL语句运行MapReduce任务</p>
<p>•可以很容易把原来构建在关系数据库上的数据仓库应用程序移植到Hadoop平台上</p>
<p>•是一个可以提供有效、合理、直观组织和使用数据的分析工具</p>
<p>Hive具有的特点非常适用于数据仓库</p>
<p>1 采用批处理方式处理海量数据</p>
<p>•Hive需要把HiveQL语句转换成MapReduce任务进行运行</p>
<p>•数据仓库存储的是静态数据，对静态数据的分析适合采用批处理方式，不需要快速响应给出结果，而且数据本身也不会频繁变化</p>
<p>2 提供适合数据仓库操作的工具</p>
<p>•Hive本身提供了一系列对数据进行提取、转换、加载（ETL）的工具，可以存储、查询和分析存储在Hadoop中的大规模数据</p>
<p>•这些工具能够很好地满足数据仓库各种应用场景</p>
<h1 id="Hive与Hadoop生态系统中其他组件的关系"><a href="#Hive与Hadoop生态系统中其他组件的关系" class="headerlink" title="Hive与Hadoop生态系统中其他组件的关系"></a>Hive与Hadoop生态系统中其他组件的关系</h1><p>•Hive 依赖于HDFS  存储数据</p>
<p>•Hive 依赖于MapReduce  处理数据</p>
<p>• 在某些场景下Pig 可以作为Hive 的替代工具</p>
<p>•HBase 提供数据的实时访问</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/2.png" alt="Hive与Hadoop生态系统中其他组件的关系"></p>
<h1 id="Hive-与传统数据库的对比分析"><a href="#Hive-与传统数据库的对比分析" class="headerlink" title="Hive 与传统数据库的对比分析"></a>Hive 与传统数据库的对比分析</h1><p>Hive在很多方面和传统的关系数据库类似，但是它的底层依赖的是HDFS和MapReduce，所以在很多方面又有别于传统数据库</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/3.png" alt="Hive 与传统数据库的对比分析"></p>
<h1 id="Hive-在企业中的部署和应用"><a href="#Hive-在企业中的部署和应用" class="headerlink" title="Hive 在企业中的部署和应用"></a>Hive 在企业中的部署和应用</h1><ol>
<li>Hive在企业大数据分析平台中的应用</li>
</ol>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/4.png" alt="Hive 在企业中的部署和应用"></p>
<ol>
<li>Hive 在Facebook 公司中的应用</li>
</ol>
<p>•基于Oracle的数据仓库系统已经无法满足激增的业务需求</p>
<p>•Facebook公司开发了数据仓库工具Hive，并在企业内部进行了大量部署</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/5.png" alt="Hive 在Facebook 公司中的应用"></p>
<h1 id="Hive系统架构"><a href="#Hive系统架构" class="headerlink" title="Hive系统架构"></a>Hive系统架构</h1><p>•用户接口模块包括CLI、HWI、JDBC、ODBC、Thrift Server</p>
<p>•驱动模块（Driver）包括编译器、优化器、执行器等，负责把HiveSQL语句转换成一系列MapReduce作业</p>
<p>•元数据存储模块（Metastore）是一个独立的关系型数据库（自带derby数据库，或MySQL数据库）</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/6.png" alt="Hive系统架构"></p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/7.png" alt="Hive对外访问接口"></p>
<h1 id="Hive-HA基本原理"><a href="#Hive-HA基本原理" class="headerlink" title="Hive HA基本原理"></a>Hive HA基本原理</h1><p>问题：在实际应用中，Hive也暴露出不稳定的问题</p>
<p>解决方案：Hive HA（High Availability）</p>
<p>•由多个Hive实例进行管理的，这些Hive实例被纳入到一个资源池中，并由HAProxy提供一个统一的对外接口</p>
<p>•对于程序开发人员来说，可以把它认为是一台超强“Hive”</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/8.png" alt="Hive HA基本原理"></p>
<h1 id="Hive工作原理"><a href="#Hive工作原理" class="headerlink" title="Hive工作原理"></a>Hive工作原理</h1><h2 id="SQL语句转换成MapReduce作业的基本原理"><a href="#SQL语句转换成MapReduce作业的基本原理" class="headerlink" title="SQL语句转换成MapReduce作业的基本原理"></a>SQL语句转换成MapReduce作业的基本原理</h2><ol>
<li>join的实现原理</li>
</ol>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/9.png" alt="join的实现原理"></p>
<ol>
<li>group by 的实现原理</li>
</ol>
<p>存在一个分组（Group By）操作，其功能是把表Score的不同片段按照rank和<br>level的组合值进行合并，计算不同rank和level的组合值分别有几条记录：<br>select rank, level ,count(*) as value from score group by rank, level</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/10.png" alt="group by 的实现原理"></p>
<h2 id="Hive中SQL查询转换成MapReduce作业的过程"><a href="#Hive中SQL查询转换成MapReduce作业的过程" class="headerlink" title="Hive中SQL查询转换成MapReduce作业的过程"></a>Hive中SQL查询转换成MapReduce作业的过程</h2><p>•当用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作：</p>
<p>•驱动模块接收该命令或查询编译器</p>
<p>•对该命令或查询进行解析编译</p>
<p>•由优化器对该命令或查询进行优化计算</p>
<p>•该命令或查询通过执行器进行执行</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/11.png" alt="Hive中SQL查询转换成MapReduce作业的过程"></p>
<p>第1步：由Hive驱动模块中的编译器对用户输入的SQL语言进行词法和语法解析，将SQL语句转化为抽象语法树的形式</p>
<p>第2步：抽象语法树的结构仍很复杂，不方便直接翻译为MapReduce算法程序，因此，把抽象语法书转化为查询块</p>
<p>第3步：把查询块转换成逻辑查询计划，里面包含了许多逻辑操作符</p>
<p>第4步：重写逻辑查询计划，进行优化，合并多余操作，减少MapReduce任务数量</p>
<p>第5步：将逻辑操作符转换成需要执行的具体MapReduce任务</p>
<p>第6步：对生成的MapReduce任务进行优化，生成最终的MapReduce任务执行计划</p>
<p>第7步：由Hive驱动模块中的执行器，对最终的MapReduce任务进行执行输出</p>
<p>几点说明：</p>
<p>• 当启动MapReduce程序时，Hive本身是不会生成MapReduce算法程序的</p>
<p>• 需要通过一个表示“Job执行计划”的XML文件驱动执行内置的、原生的Mapper和Reducer模块</p>
<p>• Hive通过和JobTracker通信来初始化MapReduce任务，不必直接部署在JobTracker所在的管理节点上执行</p>
<p>• 通常在大型集群上，会有专门的网关机来部署Hive工具。网关机的作用主要是远程操作和管理节点上的JobTracker通信来执行任务</p>
<p>• 数据文件通常存储在HDFS上，HDFS由名称节点管理</p>
<h1 id="Impala"><a href="#Impala" class="headerlink" title="Impala"></a>Impala</h1><h2 id="Impala简介"><a href="#Impala简介" class="headerlink" title="Impala简介"></a>Impala简介</h2><p>• Impala是由Cloudera公司开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase上的PB级大数据，在性能上比Hive高出3~30倍</p>
<p>• Impala的运行需要依赖于Hive的元数据</p>
<p>• Impala是参照 Dremel系统进行设计的</p>
<p>• Impala采用了与商用并行关系数据库类似的分布式查询引擎，可以直接与HDFS和HBase进行交互查询</p>
<p>• Impala和Hive采用相同的SQL语法、ODBC驱动程序和用户接口</p>
<p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/12.png" alt="Impala简介"></p>
<h2 id="Impala系统架构"><a href="#Impala系统架构" class="headerlink" title="Impala系统架构"></a>Impala系统架构</h2><p>Impala和Hive、HDFS、HBase等工具是统一部署在一个Hadoop平台上的Impala主要由Impalad，State Store和CLI三部分组成</p>
<p>图中虚线组件是Impala的组件<br><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/13.png" alt="Impala系统架构"></p>
<p>Impala主要由Impalad，State Store和CLI三部分组成</p>
<ol>
<li>Impalad</li>
</ol>
<p>• 负责协调客户端提交的查询的执行</p>
<p>• 包含Query Planner、Query Coordinator和Query Exec Engine三个模块</p>
<p>• 与HDFS的数据节点（HDFS DN）运行在同一节点上</p>
<p>• 给其他Impalad分配任务以及收集其他Impalad的执行结果进行汇总</p>
<p>• Impalad也会执行其他Impalad给其分配的任务，主要就是对本地HDFS和HBase里的部分数据进行操作</p>
<ol>
<li>State Store</li>
</ol>
<p>• 会创建一个statestored进程</p>
<p>• 负责收集分布在集群中各个Impalad进程的资源信息，用于查询调度</p>
<ol>
<li>CLI</li>
</ol>
<p>• 给用户提供查询使用的命令行工具</p>
<p>• 还提供了Hue、JDBC及ODBC的使用接口</p>
<p>说明：Impala中的元数据直接存储在Hive中。Impala采用与Hive相同的元数据、SQL语法、ODBC驱动程序和用户接口，从而使得在一个Hadoop平台上，可以统一部署Hive和Impala等分析工具，同时支持批处理和实时查询</p>
<h2 id="Impala查询执行过程"><a href="#Impala查询执行过程" class="headerlink" title="Impala查询执行过程"></a>Impala查询执行过程</h2><p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/14.png" alt="Impala查询执行过程"></p>
<p>Impala执行查询的具体过程：</p>
<p>• 第0步，当用户提交查询前，Impala先创建一个负责协调客户端提交的查询的Impalad进程，该进程会向Impala State Store提交注册订阅信息，State Store会创建一个statestored进程，statestored进程通过创建多个线程来处理Impalad的注册订阅信息。</p>
<p>• 第1步，用户通过CLI客户端提交一个查询到impalad进程，Impalad的Query Planner对SQL语句进行解析，生成解析树；然后，Planner把这个查询的解析树变成若干PlanFragment，发送到Query Coordinator</p>
<p>• 第2步，Coordinator通过从MySQL元数据库中获取元数据，从HDFS的名称节点中获取数据地址，以得到存储这个查询相关数据的所有数据节点。</p>
<p>• 第3步，Coordinator初始化相应impalad上的任务执行，即把查询任务分配给所有存储这个查询相关数据的数据节点。</p>
<p>• 第4步，Query Executor通过流式交换中间输出，并由Query Coordinator汇聚来自各个impalad的结果。</p>
<p>• 第5步，Coordinator把汇总后的结果返回给CLI客户端。</p>
<h1 id="Impala与Hive的比较"><a href="#Impala与Hive的比较" class="headerlink" title="Impala与Hive的比较"></a>Impala与Hive的比较</h1><p><img src="/2018/05/01/大数据基础学习笔记（七）——数据仓库Hive/15.png" alt="Impala与Hive的比较"></p>
<p>Hive与Impala的 不同点总结如下：</p>
<ol>
<li><p>Hive适合于长时间的批处理查询分析，而Impala适合于实时交互式SQL查询</p>
</li>
<li><p>Hive依赖于MapReduce计算框架，Impala把执行计划表现为一棵完整的执行计划树，直接分发执行计划到各个Impalad执行查询</p>
</li>
<li><p>Hive在执行过程中，如果内存放不下所有数据，则会使用外存，以保证查询能顺序执行完成，而Impala在遇到内存放不下数据时，不会利用外存，所以Impala目前处理查询时会受到一定的限制</p>
</li>
</ol>
<p>Hive与Impala的 相同点总结如下：</p>
<ol>
<li><p>Hive与Impala使用相同的存储数据池，都支持把数据存储于HDFS和HBase中</p>
</li>
<li><p>Hive与Impala使用相同的元数据</p>
</li>
<li><p>Hive与Impala中对SQL的解释处理比较相似，都是通过词法分析生成执行计划</p>
</li>
</ol>
<p>总结</p>
<p>•Impala的目的不在于替换现有的MapReduce工具</p>
<p>•把Hive与Impala配合使用效果最佳</p>
<p>•可以先使用Hive进行数据转换处理，之后再使用Impala在Hive处理后的结果数据集上进行快速的数据分析</p>
<p>转自林子雨老师的公开课  视频地址：<a href="http://www.icourse163.org/learn/XMU-1002335004#/learn/content?type=detail&amp;id=1003836807&amp;cid=1004616536&amp;replay=true" target="_blank" rel="external">http://www.icourse163.org/learn/XMU-1002335004#/learn/content?type=detail&amp;id=1003836807&amp;cid=1004616536&amp;replay=true</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（六）——MapReduce]]></title>
      <url>/2018/04/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94MapReduce/</url>
      <content type="html"><![CDATA[<h1 id="MapReduce体系结构"><a href="#MapReduce体系结构" class="headerlink" title="MapReduce体系结构"></a>MapReduce体系结构</h1><p>MapReduce主要有以下4个部分组成：</p>
<p>1 ）Client</p>
<p>•用户编写的MapReduce程序通过Client提交到JobTracker端</p>
<p>•用户可通过Client提供的一些接口查看作业运行状态</p>
<p>2 ）JobTracker</p>
<p>•JobTracker负责资源监控和作业调度</p>
<p>•JobTracker 监控所有TaskTracker与Job的健康状况，一旦发现失败，就将相应的任务转移到其他节点</p>
<p>•JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源</p>
<p>3 ）TaskTracker</p>
<p>•TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）</p>
<p>•TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task使用</p>
<p>4 ）Task</p>
<p>Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动</p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/1.png" alt="MapReduce体系结构"></p>
<h1 id="MapReduce工作流程概述"><a href="#MapReduce工作流程概述" class="headerlink" title="MapReduce工作流程概述"></a>MapReduce工作流程概述</h1><p>MapReduce把一个大的数据集拆分成多个小数据块在多台机器上并行处理，也就是说，一个大的MapReduce作业，首先会被拆分成许多个Map任务在多台机器上并行执行，每个Map任务通常运行在数据存储的节点上，这样，计算和数据就可以放在一起运行，不需要额外的数据传输开销。当Map任务结束后，会生成以<key,value>形式表示的许多中间结果。然后，这些中间结果会被分发到多个Reduce任务在多台机器上并行执行，具有相同Key的<key,value>会被发送到同一个Reduce任务那里，Reduce任务会对中间结果进行会中计算得到最后的结果，并输出到分布式文件系统中。</key,value></key,value></p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/2.png" alt="MapReduce工作流程"></p>
<p>•不同的Map任务之间不会进行通信</p>
<p>•不同的Reduce任务之间也不会发生任何信息交换</p>
<p>•用户不能显式地从一台机器向另一台机器发送消息</p>
<p>•所有的数据交换都是通过MapReduce框架自身去实现的</p>
<h1 id="MapReduce各个执行阶段"><a href="#MapReduce各个执行阶段" class="headerlink" title="MapReduce各个执行阶段"></a>MapReduce各个执行阶段</h1><p>MapReduce的算法执行过程：</p>
<p>1）MapReduce框架使用InputFormat模块做Map前的预处理，比如验证输入的格式是否符合输入定义，然后，将输入文件切分为逻辑上的多个InputSplit，这是MapReduce对文件进行处理和运算的输入单位，只是一个逻辑概念，每个InputSplit并没有对文件进行实际切割，只是记录了要处理的数据的位置和长度。</p>
<p>2）因为InuptSplit是逻辑切分而非物理切分，所以还需要通过RecordReader（RR）根据InputSplit中的信息来处理InputSplit中的具体记录，加载数据并转换为适合Map任务读取的键值对，输入给Map任务。</p>
<p>3）Map任务会根据用户自定义的映射规则，输出一系列的<key,value>作为中间结果。</key,value></p>
<p>4）为了让Reduce可以并行处理Map的结果，需要对Map的输出进行一定的分区（Portition）、排序（Sort）、合并（Combine）、归并（Merge）等操作，得到<key,value-list>形式的中间结果，在交给对应的Reduce进行处理，这个过程称为Shuffle。从无序的<key,value>到有序的<key,value-list>，这个过程用Shuffle（洗牌）来称呼是非常形象的。</key,value-list></key,value></key,value-list></p>
<p>5）Reduce以一系列<key,value-list>中间结果作为输入，执行用户定义的逻辑，输出结果给OutputFormat模块。</key,value-list></p>
<p>6）OutputFormat模块会验证输出目录是否已经存在以及输出结果类型是否符合配置文件中的配置类型，如果都满足，就输出Reduce的结果到分布式文件系统。</p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/3.png" alt="MapReduce各个执行阶段"></p>
<p>HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。</p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/4.png" alt="MapReduce各个执行阶段"></p>
<p>Map 任务的数量</p>
<p>•Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，理想的分片大小是一个HDFS块</p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/5.png" alt="Map"></p>
<p>Reduce 任务的数量</p>
<p>•最优的Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目</p>
<p>•通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误</p>
<h1 id="Shuffle过程原理"><a href="#Shuffle过程原理" class="headerlink" title="Shuffle过程原理"></a>Shuffle过程原理</h1><p>1.Shuffle 过程简介<br><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/6.png" alt="Shuffle 过程简介"></p>
<p>2.Map 端的Shuffle 过程<br><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/7.png" alt="Map 端的Shuffle 过程"></p>
<p>Map的输出结果首先被写入缓存，当缓存满时，就启动溢写操作，把缓存中的数据写入磁盘文件，并清空缓存。当启动溢写操作时，首先需要把缓存中的数据进行分区，然后对每个分区的数据进行排序（Sort）和合并（Combine），之后再写入磁盘文件。每次溢写操作会生成一个新的磁盘文件，随着Map任务的执行，磁盘中就会生成多个溢写文件。在Map任务全部结束之前，这些溢写文件会被归并（Merge）成一个大的磁盘文件，然后通知相应的Reduce任务来领取属于自己处理的数据。</p>
<p>•每个Map任务分配一个缓存</p>
<p>•MapReduce默认100MB缓存</p>
<p>•设置溢写比例0.8</p>
<p>•分区默认采用哈希函数</p>
<p>•排序是默认的操作</p>
<p>•排序后可以合并（Combine）</p>
<p>•合并不能改变最终结果</p>
<p>•在Map任务全部结束之前进行归并</p>
<p>•归并得到一个大的文件，放在本地磁盘</p>
<p>•文件归并时，如果溢写文件数量大于预定值（默<br>认是3）则可以再次启动Combiner，少于3不需要</p>
<p>•JobTracker会一直监测Map任务的执行，并通知<br>Reduce任务来领取数据</p>
<p>合并（Combine）和归并（Merge）的区别：<br>两个键值对&lt;“a”,1&gt;和&lt;“a”,1&gt;，如果合并，会得到&lt;“a”,2&gt;，如果归并，会得到&lt;“a”,<1,1>&gt;</1,1></p>
<p>3.Reduce 端的Shuffle 过程</p>
<p>Reduce任务从Map端的不同Map及其领回属于自己处理的那部分数据，然后对数据进行归并（Merge）后交给Reduce处理。</p>
<p>•Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据</p>
<p>•Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘</p>
<p>•多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的</p>
<p>•当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce</p>
<p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/8.png" alt="Reduce端的Shuffle过程"></p>
<h1 id="MapReduce应用程序执行过程"><a href="#MapReduce应用程序执行过程" class="headerlink" title="MapReduce应用程序执行过程"></a>MapReduce应用程序执行过程</h1><p><img src="/2018/04/24/大数据基础学习笔记（六）——MapReduce/9.png" alt="MapReduce应用程序执行过程"></p>
<p>参考资料：林子雨老师的MOOC课程：<br><a href="https://www.icourse163.org/learn/XMU-1002335004#/learn/content?type=detail&amp;id=1003836797&amp;cid=1004616527&amp;replay=true" target="_blank" rel="external">https://www.icourse163.org/learn/XMU-1002335004#/learn/content?type=detail&amp;id=1003836797&amp;cid=1004616527&amp;replay=true</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（五）——云数据库架构]]></title>
      <url>/2018/04/17/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%E2%80%94%E2%80%94%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9E%B6%E6%9E%84/</url>
      <content type="html"><![CDATA[<p>不同的云数据库产品采用的系统架构差异很大，这里以阿里巴巴集团核心系统数据库团队开发的UMP(Unified MySQL Platform)系统为例进行介绍。</p>
<h1 id="UMP系统概述"><a href="#UMP系统概述" class="headerlink" title="UMP系统概述"></a>UMP系统概述</h1><p>•UMP系统是低成本和高性能的MySQL云数据库方案</p>
<p>总的来说，UMP系统架构设计遵循了以下原则：</p>
<p>•保持单一的系统对外入口，并且为系统内部维护单一的资源池（CPU、内存、带宽、磁盘等放在一个统一的资源池，供上部组件调用）</p>
<p>•消除单点故障，保证服务的高可用性（设置多个管家（Controller））</p>
<p>•保证系统具有良好的可伸缩，能够动态地增加、删减计算与存储节点</p>
<p>•保证分配给用户的资源也是弹性可伸缩的，资源之间相互隔离，确保<br>应用和数据安全（多租户之间隔离，当一个用户使用过多资源时，对其进行限制，以免影响其他用户的使用）</p>
<h1 id="UMP系统架构"><a href="#UMP系统架构" class="headerlink" title="UMP系统架构"></a>UMP系统架构</h1><p><img src="/2018/04/17/大数据基础学习笔记（五）——云数据库架构/1.png" alt="UMP系统架构"></p>
<h2 id="Mnesia"><a href="#Mnesia" class="headerlink" title="Mnesia"></a>Mnesia</h2><p>•Mnesia是一个分布式数据库管理系统</p>
<p>•Mnesia支持事务，支持透明的数据分片，利用两阶段锁实现分布式事务，可以线性扩展到至少50个节点</p>
<p>•Mnesia的数据库模式(schema)可在运行时动态重配置，表能被迁移或复制到多个节点来改进容错性</p>
<p>•Mnesia的这些特性，使其在开发云数据库时被用来提供分布式数据库服务</p>
<h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><p><img src="/2018/04/17/大数据基础学习笔记（五）——云数据库架构/2.png" alt="RabbitMQ"></p>
<p>•RabbitMQ是一个工业级的消息队列产品（功能类似于IBM公司的消息<br>队列产品IBM Websphere MQ），作为消息传输中间件来使用，可以实现可靠的消息传送</p>
<p>•UMP集群中各个节点之间的通信，不需要建立专门的连接，都是通过<br>读写队列消息来实现的</p>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>Zookeeper是高效和可靠的协同工作系统，提供分布式锁之类的基本服务（比如统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等），用于构建分布式应用，减轻分布式应用程序所承担的协调任务</p>
<p>在UMP系统中，Zookeeper主要发挥三个作用：</p>
<p>•作为全局的配置服务器。UMP系统把运行的应用系统的配置信息完全交给Zookeeper来管理，把配置信息保存在Zookeeper的某个目录节点中，然后将所有需要修改的服务器对这个目录节点设置监听，也就是监控配置信息的状态，一旦配置信息发生变化，每台服务器就会收到Zookeeper的通知，然后从Zookeeper获取新的配置信息。</p>
<p>•提供分布式锁（选出一个集群的“总管”）。UMP急群众部署了多个Controller服务器，为了保证系统的正确运行，对于有些操作，在某一时刻，只能由一个服务器去执行，而不能同时执行。礼物，一个MySQL实例发生故障以后，需要进行主备切换，有另一个正常的服务器来代替当前发生故障的服务器，如果这个时候所有的Controller服务器都去跟踪处理并且发起主备切换流程，那么，整个系统就会进入混乱状态。因此，在同一时间，必须从集群的多个Controller服务器中选举出一个“总管”，由这个“总管”负责发起各种系统任务。Zookeeper的分布式锁功能能够帮助选出一个“总管”，让这个“总管”来管理集群。</p>
<p>•监控所有MySQL实例。急群众运行MySQL实例的服务器发生故障时，必须被及时监听到，然后使用其他正常服务器来替代故障服务器。UMP系统借助Zookeeper实现对所有MySQL实例的监控。每个MySQL实例在启动时都会在Zookeeper上创建一个临时类型的目录节点，当某个MySQL实例挂掉时，这个临时类型的目录节点也随之被删除，后台监听进程可以捕获到这种变化，从而知道这个MySQL实例不再可用。</p>
<h2 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h2><p>•LVS(Linux Virtual Server)即Linux虚拟服务器，是一个虚拟的服务器集群系统</p>
<p>•UMP系统借助于LVS来实现集群内部的负载均衡</p>
<p>•LVS集群采用IP负载均衡技术和基于内容请求分发技术</p>
<p>•调度器是LVS集群系统的唯一入口点，调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器</p>
<p>•整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序</p>
<h2 id="Controller服务器"><a href="#Controller服务器" class="headerlink" title="Controller服务器"></a>Controller服务器</h2><p>•Controller服务器向UMP集群提供各种管理服务，实现集群成员管理<br>、元数据存储、MySQL实例管理、故障恢复、备份、迁移、扩容等功<br>能</p>
<p>•Controller服务器上运行了一组Mnesia分布式数据库服务，其中存储了各种系统元数据，主要包括集群成员、用户的配置和状态信息，以及用户名到后端MySQL实例地址的映射关系（或称为“路由表”）等</p>
<p>•当其它服务器组件需要获取用户数据时，可以向Controller服务器发送请求获取数据</p>
<p>•为了避免单点故障，保证系统的高可用性，UMP系统中部署了多台<br>Controller服务器，然后，由Zookeeper的分布式锁功能来帮助选出一个“总管”，负责各种系统任务的调度和监控</p>
<h2 id="Web-控制台"><a href="#Web-控制台" class="headerlink" title="Web 控制台"></a>Web 控制台</h2><p>Web控制台向用户提供系统管理界面</p>
<h2 id="Proxy-服务器"><a href="#Proxy-服务器" class="headerlink" title="Proxy 服务器"></a>Proxy 服务器</h2><p>Proxy服务器向用户提供访问MySQL数据库的服务，它完全实现了<br>MySQL协议，用户可以使用已有的MySQL客户端连接到Proxy服务器，<br>Proxy服务器通过用户名获取到用户的认证信息、资源配额的限制(例如QPS、IOPS（I/O Per Second）、最大连接数等)，以及后台MySQL实例的地址，然后，用户的SQL查询请求会被转发到相应的MySQL实例上。</p>
<p>除了数据路由的基本功能外，Proxy服务器中还实现了很多重要的功能，主要包括屏蔽MySQL实例故障、读写分离、分库分表、资源隔离、记录用户访问日志等</p>
<h2 id="Agent-服务器"><a href="#Agent-服务器" class="headerlink" title="Agent 服务器"></a>Agent 服务器</h2><p>Agent服务器部署在运行MySQL进程的机器上，用来管理每台物理机上的MySQL实例，执行主从切换、创建、删除、备份、迁移等操作，同时，还负责收集和分析MySQL进程的统计信息、慢查询日志（Slow Query Log）和bin-log</p>
<h2 id="日志分析服务器"><a href="#日志分析服务器" class="headerlink" title="日志分析服务器"></a>日志分析服务器</h2><p>日志分析服务器存储和分析Proxy服务器传入的用户访问日志，并支持实时查询一段时间内的慢日志和统计报表</p>
<h2 id="信息统计服务器"><a href="#信息统计服务器" class="headerlink" title="信息统计服务器"></a>信息统计服务器</h2><p>信息统计服务器定期将采集到的用户的连接数、QPS数值以及MySQL实例的进程状态用RRDtool进行统计，可以在 Web界面上可视化展示统计结果，也可以把统计结果作为今后实现弹性的资源分配和自动化的MySQL实例迁移的依据</p>
<h2 id="愚公系统"><a href="#愚公系统" class="headerlink" title="愚公系统"></a>愚公系统</h2><p>愚公系统是一个全量复制结合bin-log分析进行增量复制的工具，可以实现在不停机的情况下动态扩容、缩容和迁移</p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（四）——HBase相关知识（三）]]></title>
      <url>/2018/04/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%E2%80%94%E2%80%94HBase%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%89%EF%BC%89/</url>
      <content type="html"><![CDATA[<h1 id="HBase应用方案"><a href="#HBase应用方案" class="headerlink" title="HBase应用方案"></a>HBase应用方案</h1><h2 id="HBase实际应用中的性能优化方法"><a href="#HBase实际应用中的性能优化方法" class="headerlink" title="HBase实际应用中的性能优化方法"></a>HBase实际应用中的性能优化方法</h2><p><code>行键（Row Key ）</code></p>
<p>行键是按照 字典序存储，因此，设计行键时，要充分利用这个排序特点，将经常一起读取的数据存储到一块，将最近可能会被访问的数据放在一块。</p>
<p>举个例子：如果最近写入HBase表中的数据是最可能被访问的，可以考虑将时间戳<br>作为行键的一部分，由于是字典序排序，所以可以使用Long.MAX_VALUE -<br>timestamp作为行键，这样能保证新写入的数据在读取时可以被快速命中。</p>
<p><img src="/2018/04/03/大数据基础学习笔记（四）——HBase相关知识（三）/1.png" alt="行键"></p>
<p><code>InMemory</code><br>创建表的时候，可以通过HColumnDescriptor.setInMemory(true)将表放到Region服务器的缓存中，保证在读取的时候被cache命中。</p>
<p><code>Max Version</code><br>创建表的时候，可以通过HColumnDescriptor.setMaxVersions(int maxVersions)设置表中数据的最大版本，如果只需要保存最新版本的数据，那么可以设置setMaxVersions(1)。</p>
<p><code>Time To Live</code><br>创建表的时候，可以通过HColumnDescriptor.setTimeToLive(int timeToLive)设置表中数据的存储生命期，过期数据将自动被删除，例如如果只需要存储最近两天的数据，那么可以设置setTimeToLive(2 <em> 24 </em> 60 * 60)。</p>
<h2 id="HBase性能监视"><a href="#HBase性能监视" class="headerlink" title="HBase性能监视"></a>HBase性能监视</h2><p><code>Master-status(自带)</code></p>
<p>•HBase Master默认基于Web的UI服务端口为60010，HBase region服务器默认基于Web的UI服务端口为60030.如果master运行在名为master.foo.com的主机中，mater的主页地址就是<a href="http://master.foo.com:60010，用户可以通过Web浏览器输入这个地址查看该页面" target="_blank" rel="external">http://master.foo.com:60010，用户可以通过Web浏览器输入这个地址查看该页面</a></p>
<p>•可以查看HBase集群的当前状态</p>
<p><code>Ganglia</code></p>
<p>Ganglia是UC Berkeley发起的一个开源集群监视项目，用于监控系统性能</p>
<p><code>OpenTSDB</code></p>
<p>OpenTSDB可以从大规模的集群（包括集群中的网络设备、操作系统、应用程序）中获取相应的metrics并进行存储、索引以及服务，从而使得这些数据更容易让人理解，如web化，图形化等</p>
<p><code>Ambari</code></p>
<p>Ambari 的作用就是创建、管理、监视 Hadoop 的集群</p>
<h2 id="在HBase之上构建SQL引擎"><a href="#在HBase之上构建SQL引擎" class="headerlink" title="在HBase之上构建SQL引擎"></a>在HBase之上构建SQL引擎</h2><p>NoSQL区别于关系型数据库的一点就是NoSQL不使用SQL作为查询语言，至于为何在NoSQL数据存储HBase上提供SQL接口，有如下原因：</p>
<ol>
<li><p>易使用。使用诸如SQL这样易于理解的语言，使人们能够更加轻松地使用HBase。</p>
</li>
<li><p>减少编码。使用诸如SQL这样更高层次的语言来编写，减少了编写的代码量。<br>方案：</p>
</li>
</ol>
<p>1.Hive整合HBase<br>2.Phoenix</p>
<p>1.Hive 整合HBase</p>
<p>Hive与HBase的整合功能从Hive0.6.0版本已经开始出现，利用两者对外的API接口互相通信，通信主要依靠hive_hbase-handler.jar工具包(Hive Storage Handlers)。由于HBase有一次比较大的版本变动，所以并不是每个版本的Hive都能和现有的HBase版本进行整合，所以在使用过程中特别注意的就是两者版本的一致性。</p>
<p>2.Phoenix</p>
<p>Phoenix由Salesforce.com开源，是构建在Apache HBase之上的一个SQL中间层，可以让开发者在HBase上执行SQL查询。</p>
<h2 id="构建HBase二级索引"><a href="#构建HBase二级索引" class="headerlink" title="构建HBase二级索引"></a>构建HBase二级索引</h2><p>二级索引，又叫辅助索引</p>
<p>HBase只有一个针对行健的索引访问HBase表中的行，只有三种方式：</p>
<p>•通过单个行健访问</p>
<p>•通过一个行健的区间来访问</p>
<p>•全表扫描</p>
<p>使用其他产品为HBase行健提供索引功能：</p>
<p>•Hindex二级索引</p>
<p>•HBase+Redis</p>
<p>•HBase+solr</p>
<p>原理：采用HBase0.92版本之后引入的Coprocessor特性</p>
<p><img src="/2018/04/03/大数据基础学习笔记（四）——HBase相关知识（三）/2.png" alt="二级索引"></p>
<p><code>Coprocessor构建二级索引</code></p>
<p>•Coprocessor提供了两个实现：endpoint和observer，endpoint相当于关系型数据库的<br>存储过程，而observer则相当于触发器</p>
<p>•observer允许我们在记录put前后做一些处理，因此，而我们可以在插入数据时同步写<br>入索引表</p>
<p>•Coprocessor构建二级索引•缺点：每插入一条数据需要向索引表插入数据，即耗时是双倍的，对HBase的集群的压力也是双倍的</p>
<p>优点：<br>非侵入性：引擎构建在HBase之上，既没有对HBase进行任何改动，也不需要上层应用做任何妥协</p>
<p>Hindex二级索引</p>
<p>Hindex 是华为公司开发的纯 Java 编写的HBase二级索引，兼容 Apache HBase 0.94.8。当前的特性如下：</p>
<p>•多个表索引</p>
<p>•多个列索引</p>
<p>•基于部分列值的索引</p>
<p><code>HBase+Redis</code></p>
<p>•Redis+HBase方案</p>
<p>•Coprocessor构建二级索引</p>
<p>•Redis做客户端缓存</p>
<p>•将索引实时更新到Redis等KV系统中，定时从KV更新索引到HBase的索引表中</p>
<p><img src="/2018/04/03/大数据基础学习笔记（四）——HBase相关知识（三）/3.png" alt="HBase+Redis"></p>
<p><code>Solr+HBase</code></p>
<p>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行<br>了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询<br>性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索<br>引擎。</p>
<p><img src="/2018/04/03/大数据基础学习笔记（四）——HBase相关知识（三）/4.png" alt="Solr+HBase"></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（三）——HBase相关知识（二）]]></title>
      <url>/2018/04/02/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94HBase%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
      <content type="html"><![CDATA[<h1 id="HBase功能组件"><a href="#HBase功能组件" class="headerlink" title="HBase功能组件"></a>HBase功能组件</h1><p>• HBase的实现包括三个主要的功能组件：<br>– （1）库函数：链接到每个客户端<br>– （2）一个Master主服务器（充当管家的作用）<br>– （3）许多个Region服务器</p>
<p>• 主服务器Master负责管理和维护HBase表的分区信息，维护Region服务器列表，分配Region，负载均衡</p>
<p>• 一个大的表会被分成很多个Region，Region服务器负责存储和维护分配给自己的Region，处理来自客户端的读写请求</p>
<p>• 客户端并不是直接从Master主服务器上读取数据，而是在获得Region的存储位置信息后，直接从Region服务器上读取数据</p>
<p>• 客户端并不依赖Master，而是通过Zookeeper来获得Region位置信息，大多数客户端甚至从来不和Master通信，这种设计方式使得Master负载很小</p>
<h2 id="表和Region"><a href="#表和Region" class="headerlink" title="表和Region"></a>表和Region</h2><p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/1.png" alt="一个HBase表被划分成多个Region"></p>
<p>•开始只有一个Region，后来不断分裂</p>
<p>•Region拆分操作非常快，接近瞬间，因为拆分之后的Region读取的仍然是原存储文件，直到“合并”过程把存储文件异步地写到独立的文件之后，才会读取新文件</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/2.png" alt="一个Region会分裂成多个新的Region"></p>
<p>这种拆分只是逻辑上的拆分，只是数据的指向发生了变化，它的实际存储还是在原来的旧的Region中的数据。<br>当读新的Region时，后台会有一个合并操作，会把拆分的数据进行重新操作，最终会写到新的文件中去。</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/3.png" alt="不同的Region可以分布在不同的Region服务器上"></p>
<p>一个Region只能存到一个Region服务器上。</p>
<h2 id="Region的定位"><a href="#Region的定位" class="headerlink" title="Region的定位"></a>Region的定位</h2><p>那么有一个问题，当一个Region被拆成很多个Region时，这些Region会把它打散，分布到不同的地方存储，那么怎么知道它被存到哪里去了呢？</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/4.png" alt="映射表"></p>
<p>•元数据表，又名.META.表，存储了Region和Region服务器的映射关系</p>
<p>•当HBase表很大时， .META.表也会被分裂成多个Region</p>
<p>•根数据表，又名-ROOT-表，记录所有元数据的具体位置</p>
<p>•-ROOT-表只有唯一一个Region，名字是在程序中被写死的</p>
<p>•Zookeeper文件记录了-ROOT-表的位置</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/5.png" alt="HBase的三层结构"></p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/6.png" alt="HBase的三层结构中各层次的名称和作用"></p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/7.png" alt="Region定位"></p>
<p>•一个-ROOT-表最多只能有一个Region，也就是最多只能有128MB，按照每行（一个映射条目）占用1KB内存计算，128MB空间可以容纳128MB/1KB=2^17 行，也就是说，一个-ROOT-表可以寻址2^17 个.META.表的Region。</p>
<p>•同理，每个.META.表的 Region可以寻址的用户数据表的Region个数是128MB/1KB=2^17 。</p>
<p>•最终，三层结构可以保存的Region数目是(128MB/1KB) × (128MB/1KB) = 2^34 个Region</p>
<p>所以三层架构能够满足企业的需求。</p>
<p>客户端访问数据时的“三级寻址”<br>•为了加速寻址，客户端会缓存位置信息，同时，需要解决缓存失效问题</p>
<p>•寻址过程客户端只需要询问Zookeeper服务器，不需要连接Master服务器</p>
<p>这里的缓存机制采用的是惰性缓存，如果在使用缓存获取数据时，获取不到数据，那么就失效了，这时候再次进行三级寻址过程，以解决缓存失效问题。</p>
<h1 id="HBase运行机制"><a href="#HBase运行机制" class="headerlink" title="HBase运行机制"></a>HBase运行机制</h1><p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/8.png" alt="HBase的系统架构"></p>
<p>• 1. 客户端<br>– 客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程</p>
<p>• 2. Zookeeper服务器<br>– Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题Zookeeper是一个很好的集群管理工具，被大量用于分布式计算，提供配置维护、域名服务、分布式同步、组服务等。提供管家的功能，维护整个HBase集群。虽然有很多备用的Master，但是它保证只有一个Master是运行的。</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/9.png" alt="ZooKeeper"></p>
<p>• 3. Master<br>• 主服务器Master主要负责表和Region的管理工作：<br>– 管理用户对表的增加、删除、修改、查询等操作<br>– 实现不同Region服务器之间的负载均衡<br>– 在Region分裂或合并后，负责重新调整Region的分布<br>– 对发生故障失效的Region服务器上的Region进行迁移</p>
<p>• 4. Region服务器<br>– Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/10.png" alt="Region服务器向HDFS文件系统中读写数据"></p>
<h2 id="Region服务器工作原理"><a href="#Region服务器工作原理" class="headerlink" title="Region服务器工作原理"></a>Region服务器工作原理</h2><p>1.用户读写数据过程</p>
<p>•用户写入数据时，被分配到相应Region服务器去执行</p>
<p>•用户数据首先被写入到MemStore和Hlog中</p>
<p>•只有当操作写入Hlog之后，commit()调用才会将其返回给客户端</p>
<p>•当用户读取数据时，Region服务器会首先访问MemStore缓存，如果找不到，再去磁盘上面的StoreFile中寻找</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/11.png" alt="用户读写数据过程"></p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/12.png" alt="用户读写数据过程"></p>
<p>2.缓存的刷新</p>
<p>•系统会周期性地把MemStore缓存里的内容刷写到磁盘的StoreFile文件中，清空缓存，并在Hlog里面写入一个标记</p>
<p>•每次刷写都生成一个新的StoreFile文件，因此，每个Store包含多个StoreFile文件</p>
<p>•每个Region服务器都有一个自己的HLog 文件，每次启动都检查该文件，确认最近一次执行缓存刷新操作之后是否发生新的写入操作；如果发现更新，则先写入MemStore，再刷写到StoreFile，最后删除旧的Hlog文件，开始为用户提供服务</p>
<p>3.StoreFile 的合并</p>
<p>•每次刷写都生成一个新的StoreFile，数量太多，影响查找速度</p>
<p>•调用Store.compact()把多个合并成一个</p>
<p>•合并操作比较耗费资源，只有数量达到一个阈值才启动合并</p>
<h2 id="Store工作原理"><a href="#Store工作原理" class="headerlink" title="Store工作原理"></a>Store工作原理</h2><p>•Store是Region服务器的核心</p>
<p>•多个StoreFile合并成一个</p>
<p>•单个StoreFile过大时，又触发分裂操作，1个父Region被分裂成两个子Region</p>
<p><img src="/2018/04/02/大数据基础学习笔记（三）——HBase相关知识（二）/13.png" alt="StoreFile的合并和分裂过程"></p>
<h2 id="HLog工作原理"><a href="#HLog工作原理" class="headerlink" title="HLog工作原理"></a>HLog工作原理</h2><p>• 分布式环境必须要考虑系统出错。HBase采用HLog保证系统恢复</p>
<p>• HBase系统为每个Region服务器配置了一个HLog文件，它是一种预<br>写式日志（Write Ahead Log）</p>
<p>• 用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且<br>，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘</p>
<p>• Zookeeper会实时监测每个Region服务器的状态，当某个Region服<br>务器发生故障时，Zookeeper会通知Master</p>
<p>• Master首先会处理该故障Region服务器上面遗留的HLog文件，这个遗留的HLog文件中包含了来自多个Region对象的日志记录</p>
<p>• 系统会根据每条日志记录所属的Region对象对HLog数据进行拆分，<br>分别放到相应Region对象的目录下，然后，再将失效的Region重新<br>分配到可用的Region服务器中，并把与该Region对象相关的HLog日<br>志记录也发送给相应的Region服务器</p>
<p>• Region服务器领取到分配给自己的Region对象以及与之相关的HLog日志记录以后，会重新做一遍日志记录中的各种操作，把日志记录中的数据写入到MemStore缓存中，然后，刷新到磁盘的StoreFile文件中，完成数据恢复</p>
<p>• 共用日志优点：提高对表的写操作性能；缺点：恢复时需要分拆日志</p>
<p>本笔记参考自厦门大学林子雨老师的公开课：<a href="https://www.icourse163.org/course/XMU-1002335004" target="_blank" rel="external">https://www.icourse163.org/course/XMU-1002335004</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（二）——HBase相关知识（一）]]></title>
      <url>/2018/04/02/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94Hbase%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</url>
      <content type="html"><![CDATA[<h1 id="Hbase简介"><a href="#Hbase简介" class="headerlink" title="Hbase简介"></a>Hbase简介</h1><p>HBase是一个高可靠、高性能、面向列、可伸缩的分布式数据库，是谷歌BigTable的开源实现，主要用来存储非结构化和半结构化的松散数据。HBase的目标是处理非常庞大的表，可以通过水平扩展的方式，利用廉价计算机集群处理由超过10亿行数据和数百万列元素组成的数据表。</p>
<p>底层的分布式文件系统用来存储完全非结构化的数据。</p>
<p>Hbase是架构在底层的分布式文件系统HDFS基础之上的同时MR可以对Hbase的数据进行处理。同时Hive和Pig等都可以访问Hbase中的数据。</p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/1.png" alt="Hbase和Big Table的底层技术对应关系"></p>
<p>从上图可以看出，BigTable和HBase的底层技术的对比。</p>
<h2 id="为什么要设计HBase这个数据产品呢？"><a href="#为什么要设计HBase这个数据产品呢？" class="headerlink" title="为什么要设计HBase这个数据产品呢？"></a>为什么要设计HBase这个数据产品呢？</h2><p>•Hadoop可以很好地解决大规模数据的离线批量处理问题，但是，受限于HadoopMapReduce编程框架的高延迟数据处理机制，使得Hadoop无法满足大规模数据实时处理应用的需求</p>
<p>•HDFS面向批量访问模式，不是随机访问模式</p>
<p>•传统的通用关系型数据库无法应对在数据规模剧增时导致的系统扩展性和性能问题（分库分表也不能很好解决）</p>
<p>•传统关系数据库在数据结构变化时一般需要停机维护；空列浪费存储空间</p>
<p>•因此，业界出现了一类面向半结构化数据存储和处理的高可扩展、低写入/查询延迟的系统，例如，键值数据库、文档数据库和列族数据库（如BigTable和HBase等）</p>
<p>•HBase已经成功应用于互联网服务领域和传统行业的众多在线式数据分析处理系统中</p>
<h2 id="HBase与传统关系数据库的对比分析"><a href="#HBase与传统关系数据库的对比分析" class="headerlink" title="HBase与传统关系数据库的对比分析"></a>HBase与传统关系数据库的对比分析</h2><p>• HBase与传统的关系数据库的区别主要体现在以下几个方面：</p>
<p>• （1）数据类型：关系数据库采用关系模型，具有丰富的数据类型（整型，字符型等等）和存储方式，HBase则采用了更加简单的数据模型，它把数据存储为未经解释的字符串（也就是Bytes数组）</p>
<p>• （2）数据操作：关系数据库中包含了丰富的操作（增删改查），其中会涉及复杂的多表连接。HBase操作则不存在复杂的表与表之间的关系，只有简单的插入、查询、删除、清空等，因为HBase在设计上就避免了复杂的表和表之间的关系</p>
<p>• （3）存储模式：关系数据库是基于行模式存储的。HBase是基于列存储的，每个列族都由几个文件保存，不同列族的文件是分离的</p>
<p>• （4）数据索引：关系数据库通常可以针对不同列构建复杂的多个索引，以提高数据访问性能。HBase只有一个索引——行键，通过巧妙的设计，HBase中的所有访问方法，或者通过行键访问，或者通过行键扫描，从而使得整个系统不会慢下来</p>
<p>• （5）数据维护：在关系数据库中，更新操作会用最新的当前值去替换记录中原来的旧值，旧值被覆盖后就不会存在。而在HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留，只有在过了设置的参数期限之后，在系统后台清理的时候才会清理掉</p>
<p>• （6）可伸缩性：关系数据库很难实现横向扩展，纵向扩展（如添加内存，改进CPU等等）的空间也比较有限。相反，HBase和BigTable这些分布式数据库就是为了实现灵活的水平扩展而开发的，能够轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩</p>
<h2 id="HBase的访问接口"><a href="#HBase的访问接口" class="headerlink" title="HBase的访问接口"></a>HBase的访问接口</h2><p>以后在使用Hbase的时候，可以通过哪些方式访问HBase数据库？<br>见下图：<br><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/2.png" alt="HBase访问接口"></p>
<h2 id="HBase数据模型"><a href="#HBase数据模型" class="headerlink" title="HBase数据模型"></a>HBase数据模型</h2><p>• HBase是一个稀疏、多维度、排序的映射表，这张表的索引是行键、列族、列限定符和时间戳</p>
<p>• 每个值是一个未经解释的字符串，没有数据类型</p>
<p>• 用户在表中存储数据，每一行都有一个可排序的行键和任意多的列</p>
<p>• 表在水平方向由一个或者多个列族组成，一个列族中可以包含任意多个列，同一个列族里面的数据存储在一起</p>
<p>• 列族支持动态扩展，可以很轻松地添加一个列族或列，无需预先定义列的数量以及类型，所有列均以字符串形式存储，用户需要自行进行数据类型转换</p>
<p>• HBase中执行更新操作时，并不会删除数据旧的版本，而是生成一个新的版本，旧有的版本仍然保留（这是和HDFS只允许追加不允许修改的特性相关的）</p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/3.png" alt="HBase访问接口"></p>
<p>• 表：HBase采用表来组织数据，表由行和列组成，列划分为若干个列族</p>
<p>• 行：每个HBase表都由若干行组成，每个行由行键（row key）来标识。</p>
<p>• 列族：一个HBase表被分组成许多“列族”（Column Family）的集合，它是基本的访问控制单元（支持动态拓展）</p>
<p>• 列限定符：列族里的数据通过列限定符（或列）来定位</p>
<p>• 单元格：在HBase表中，通过行、列族和列限定符确定一个“单元格”（cell），单元格中存储的数据没有数据类型，总被视为字节数组byte[]</p>
<p>• 时间戳：每个单元格都保存着同一份数据的多个版本，这些版本采用时间戳进行索引</p>
<h3 id="HBase的数据坐标"><a href="#HBase的数据坐标" class="headerlink" title="HBase的数据坐标"></a>HBase的数据坐标</h3><p>HBase中需要根据行键、列族、列限定符和时间戳来确定一个单元格，因此，可以视为一个“四维坐标”，即[行键, 列族, 列限定符, 时间戳]</p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/4.png" alt="HBase数据坐标"></p>
<h3 id="概念视图"><a href="#概念视图" class="headerlink" title="概念视图"></a>概念视图</h3><p>HBase在概念上和实际的底层存储是有区分的，在概念上HBase只是一个表，如下面只给了一个行键：</p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/5.png" alt="概念视图"><br>如这一个行键给了两个列族，第一个列族contents中冒号前面的contents是列族的名称，冒号后面的html是列的名称，引号中的内容就是这一列的数据。一个时间戳并不一定会在所有列族插入数据，从图中就可以看出。所以这就导致了HBase的稀疏表的特性。这只是在概念上的视图。</p>
<h3 id="物理视图"><a href="#物理视图" class="headerlink" title="物理视图"></a>物理视图</h3><p>实际上在实际存储中，并不是按上述的方式去存的。在底层存储时，是按列族为单位进行存储的。</p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/6.png" alt="HBase数据的物理视图"></p>
<p>上图是在实际存储时，存储在底层的实际的表。并没有像概念视图中存储了很多的空数据。所以概念视图和物理视图上是有区分的。</p>
<h3 id="面向列的存储"><a href="#面向列的存储" class="headerlink" title="面向列的存储"></a>面向列的存储</h3><p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/8.png" alt="行式数据库和列式数据库示意图"></p>
<p><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/7.png" alt="行式存储结构和列式存储结构"></p>
<p>传统的数据库，以行为单位进行存储，一行包括ID,姓名，年龄，性别，IP，操作等。<br>但是按列存储，里面的姓名、年龄等进行单独存储。</p>
<p>它们各自的优缺点：<br><img src="/2018/04/02/大数据基础学习笔记（二）——Hbase相关知识/9.png" alt="行式存储结构和列式存储结构"></p>
<p>另外，使用列式存储，数据可以达到很高的数据压缩率。而行式存储，很难压缩。</p>
<p>本笔记参考自厦门大学林子雨老师的公开课：<a href="https://www.icourse163.org/course/XMU-1002335004" target="_blank" rel="external">https://www.icourse163.org/course/XMU-1002335004</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[大数据基础学习笔记（一）——Hadoop相关知识]]></title>
      <url>/2018/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop的应用现状和构成简介"><a href="#Hadoop的应用现状和构成简介" class="headerlink" title="Hadoop的应用现状和构成简介"></a>Hadoop的应用现状和构成简介</h2><p>下图为Hadoop在企业中的 应用架构</p>
<p><img src="/2018/04/01/大数据基础学习笔记/1.png" alt="Hadoop在企业中的应用架构"></p>
<p>访问层不用多说，满足企业的数据分析、数据挖掘和数据实时查询功能。<br>为了满足访问层的需求，大数据层的各个技术对其进行支撑。<br>（1）离线分析：大量数据拿过来之后进行批量处理。其中MR是MapReduce的简称，Hive数据仓库和Pig也可以进行离线数据分析。<br>（2）实时查询：其中Hbase是一个可以支持几十亿行数据的非常好的分布式数据库。<br>（3）BI分析：Mahout是Hadoop平台上的一款数据挖掘应用。可以把各种数据挖掘，机器学习和商务智能的算法用MapReduce实现。否则开发人员要自己用MapReduce写决策树算法。</p>
<p>下图为一些大数据计算模式及其代表产品</p>
<p><img src="/2018/04/01/大数据基础学习笔记/2.png" alt="大数据计算模式及其代表产品"></p>
<p>下图为Hadoop项目结构</p>
<p><img src="/2018/04/01/大数据基础学习笔记/3.png" alt="Hadoop项目结构"></p>
<p>YARNz专门负责调度内存，CPU，带宽等计算资源。而上面的事完成具体的计算工作的。</p>
<p>Tez会把很多的MapReduce作业进行分析优化，构建成一个有向无环图，保证获得最好的处理效率。</p>
<p>Spark与MapReduce类似，也是进行相应的计算。但是Spark是基于内存的，而MapReduce是基于磁盘的计算。MR在计算时，先把数据写到磁盘中，然后c处理结束后再写到分布式文件系统中。所以Spark的性能要高。</p>
<p>Pig实现流数据处理，较MR属于轻量级。它也支持类似于SQL的语句。是一种轻量级的脚本语言。</p>
<p>Oozie是一个工作流管理系统，可以把一个工作分成不同的工作环节。</p>
<p>Zookeeper提供分布式协调一致性服务。</p>
<p>Hbase是一个非关系型数据库，可以支持随机读写。</p>
<p>Flume是专门负责日志收集的，分析一些实时生成的数据流。</p>
<p>Sqoopy用于在Hadoop与传统数据库之间进行数据传递（导入导出等）。可以把之前存到关系型数据库（如Oracle）中的数据导入到HDFS、Hive或者Hbase中，反之亦可。</p>
<p>Ambari是一个安装部署工具，可以在一个集群上面智能化的管理一整套Hadoop上的各个套件。</p>
<p>Hadoop各组件的功能如下：</p>
<p><img src="/2018/04/01/大数据基础学习笔记/4.png" alt="Hadoop组件及功能"></p>
<h2 id="Hadoop集群的节点类型"><a href="#Hadoop集群的节点类型" class="headerlink" title="Hadoop集群的节点类型"></a>Hadoop集群的节点类型</h2><p>Hadoop框架中最核心的设计是为海量数据提供存储的<code>HDFS</code>和对数据进行计算的<code>MapReduce</code></p>
<p>MapReduce的作业主要包括：<br>（1）从磁盘或从网络读取数据，即IO密集工作；<br>（2）计算数据，即CPU密集工作</p>
<p>•Hadoop集群的整体性能取决于CPU、内存、网络以及存储之间的性能平衡。因此运营团队在选择机器配置时要针对不同的工作节点选择合适硬件类型<br>•一个基本的Hadoop集群中的节点主要有:</p>
<p>•NameNode：负责协调集群中的数据存储</p>
<p>•DataNode：存储被拆分的数据块</p>
<p>•JobTracker：协调数据计算任务</p>
<p>•TaskTracker：负责执行由JobTracker指派的任务</p>
<p>•SecondaryNameNode：帮助NameNode收集文件系统运行的状态信息</p>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>全称：Hadoop Distributed File System.解决海量数据的分布式存储问题。</p>
<h2 id="分布式文件系统的结构"><a href="#分布式文件系统的结构" class="headerlink" title="分布式文件系统的结构"></a>分布式文件系统的结构</h2><p>分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)</p>
<p><img src="/2018/04/01/大数据基础学习笔记/5.png" alt="大规模文件系统的整体结构"></p>
<p>HDFS的三个节点：Namenode，Datanode，Secondary Namenode</p>
<p>Namenode：HDFS的守护进程，用来管理文件系统的命名空间，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到那些数据节点上，它的主要功能是对内存及IO进行集中管理。</p>
<p>Datanode：文件系统的工作节点，根据需要存储和检索数据块，并且定期向namenode发送他们所存储的块的列表。</p>
<p>Secondary Namenode：辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照。</p>
<p>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（<br>NameNode）和若干个数据节点（DataNode）（如图所示）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的。</p>
<p><img src="/2018/04/01/大数据基础学习笔记/10.png" alt="HDFS体系结构"><br>HDFS的缺点：</p>
<p>1.不适合低延迟的数据访问<br>2.无法高效存储大量小文件<br>3.不支持多用户写入及任意修改文件</p>
<h3 id="名称节点和数据节点"><a href="#名称节点和数据节点" class="headerlink" title="名称节点和数据节点"></a>名称节点和数据节点</h3><p><img src="/2018/04/01/大数据基础学习笔记/7.png" alt="HDFS主要组件的功能"></p>
<p>在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog。</p>
<p>•FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据</p>
<p>•操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作</p>
<p>•名称节点记录了每个文件中各个块所在的数据节点的位置信息。</p>
<p><img src="/2018/04/01/大数据基础学习笔记/6.png" alt="名称节点的数据结构"></p>
<p>客户端在访问数据时，先通过名称节点，获取元数据信息，从而知道被访问的数据存到哪些数据节点，获得数据块具体存储位置的信息之后，客户端就会到各个机器上去获取它所需要的数据。写入操作类似，客户端先访问名称节点，一个大文件（如1TB,2TB）要怎么写，然后名称节点会告诉它，把文件分成多少块，每个块放到哪个数据节点上。</p>
<p><img src="/2018/04/01/大数据基础学习笔记/9.png" alt="局限性"></p>
<h4 id="FsImage-文件"><a href="#FsImage-文件" class="headerlink" title="FsImage 文件"></a>FsImage 文件</h4><p>•FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据</p>
<p>•FsImage文件没有记录块存储在哪个数据节点。而是由名称节点把这些映射保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。</p>
<p>在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行<br>EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</p>
<p>•一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件</p>
<p>•名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新</p>
<h4 id="第二名称节点"><a href="#第二名称节点" class="headerlink" title="第二名称节点"></a>第二名称节点</h4><p>第二名称节点是HDFS架构中的一个组成部分，它是用来保存名称节点中对HDFS 元<br>数据信息的备份，并减少名称节点重启的时间。SecondaryNameNode一般是单独运行在一台机器上。</p>
<p><img src="/2018/04/01/大数据基础学习笔记/8.png" alt=""></p>
<p>SecondaryNameNode的工作情况：</p>
<p>（1）SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</p>
<p>（2）SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；</p>
<p>（3）SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</p>
<p>（4）SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上；</p>
<p>（5）NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小。</p>
<h4 id="数据节点（DataNode）"><a href="#数据节点（DataNode）" class="headerlink" title="数据节点（DataNode）"></a>数据节点（DataNode）</h4><p>数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客<br>户端或者是名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表</p>
<p>•每个数据节点中的数据会被保存在各自节点的本地Linux文件系统中</p>
<h2 id="HDFS存储原理"><a href="#HDFS存储原理" class="headerlink" title="HDFS存储原理"></a>HDFS存储原理</h2><h3 id="冗余数据保存"><a href="#冗余数据保存" class="headerlink" title="冗余数据保存"></a>冗余数据保存</h3><p>作为一个分布式文件系统，为了保证系统的容错性和可用性，HDFS采用了多副<br>本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上，数据块1被分别存放到数据节点A和C上，数据块2被存放在数据节点A和B上。这种多副本方式具有以下几个优点：<br>（1） 加快数据传输速度</p>
<p>（2） 容易检查数据错误</p>
<p>（3） 保证数据可靠性</p>
<p><img src="/2018/04/01/大数据基础学习笔记/11.png" alt="HDFS数据块多副本存储"></p>
<h3 id="数据存取策略"><a href="#数据存取策略" class="headerlink" title="数据存取策略"></a>数据存取策略</h3><h4 id="数据存放"><a href="#数据存放" class="headerlink" title="数据存放"></a>数据存放</h4><p>•第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点</p>
<p>•第二个副本：放置在与第一个副本不同的机架的节点上</p>
<p>•第三个副本：与第一个副本相同机架的其他节点上</p>
<p>•更多副本：随机节点</p>
<p><img src="/2018/04/01/大数据基础学习笔记/12.png" alt="Block的副本放置策略"></p>
<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4><p>•HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API<br>获取自己所属的机架ID</p>
<p>•当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据</p>
<h3 id="数据错误与恢复"><a href="#数据错误与恢复" class="headerlink" title="数据错误与恢复"></a>数据错误与恢复</h3><p>HDFS具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看作一种常态，<br>而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括以下几种情形：名称节点出错、数据节点出错和数据出错。</p>
<h4 id="名称节点出错"><a href="#名称节点出错" class="headerlink" title="名称节点出错"></a>名称节点出错</h4><p>名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是FsImage和Editlog，如果这两个文件发生损坏，那么整个HDFS实例将失效。因此，HDFS设<br>置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和<br>Editlog数据进行恢复。</p>
<h4 id="数据节点出错"><a href="#数据节点出错" class="headerlink" title="数据节点出错"></a>数据节点出错</h4><p>•每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态</p>
<p>•当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求</p>
<p>•这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的副本数量小于冗余因子•名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本</p>
<p>•HDFS和其它分布式文件系统的最大区别就是可以调整冗余数据的位置</p>
<h4 id="数据出错"><a href="#数据出错" class="headerlink" title="数据出错"></a>数据出错</h4><p>•网络传输和磁盘错误等因素，都会造成数据错误</p>
<p>•客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据</p>
<p>•在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面</p>
<p>•当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块</p>
<p>本笔记的来源源自林子雨老师的MOOC课程和课件，地址：<a href="https://www.icourse163.org/course/XMU-1002335004" target="_blank" rel="external">https://www.icourse163.org/course/XMU-1002335004</a></p>
]]></content>
      
        
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[git学习]]></title>
      <url>/2018/02/01/git%E5%AD%A6%E4%B9%A0/</url>
      <content type="html"><![CDATA[<p><img src="/2018/02/01/git学习/git.jpg" alt="git"><br><a id="more"></a></p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p><img src="/2018/02/01/git学习/1.jpg" alt="安装成功"></p>
<p>在命令行输入<code>git --version</code>如果显示版本信息则说明安装成功，否则要去官网进行安装。</p>
<h2 id="Visual-Studio-Code-启用bash"><a href="#Visual-Studio-Code-启用bash" class="headerlink" title="Visual Studio Code 启用bash"></a>Visual Studio Code 启用bash</h2><p>VS Code默认的终端窗口是只带cmd功能的，如果要在终端中唤出bash要进行配置：</p>
<p>首先找到本机的<code>bash.exe</code>的目录,比如我的目录如图：</p>
<p><img src="/2018/02/01/git学习/3.jpg" alt="bash.exe"></p>
<p>然后在<code>VS Code</code>-&gt;<code>首选项</code>-&gt;<code>设置</code>-&gt;搜索<code>terminal.integrated.shell.windows</code>-&gt;将<code>&quot;terminal.integrated.shell.windows&quot;: &quot;C:\\Program Files\\Git\\bin\\bash.exe&quot;</code>放入设置中-&gt;保存</p>
<p><img src="/2018/02/01/git学习/4.jpg" alt="配置"></p>
<p>重新启动VS Code可以看到自动进入bash命令窗口</p>
<p><img src="/2018/02/01/git学习/5.jpg" alt="bash终端命令窗口"></p>
<p>如果想切换到cmd命令窗口直接输入<code>cmd</code>回车即可,同理在cmd下切换到<code>bash</code>只需输入<code>bash</code>回车：</p>
<p><img src="/2018/02/01/git学习/6.jpg" alt="bash切换到cmd"></p>
<h1 id="仓库"><a href="#仓库" class="headerlink" title="仓库"></a>仓库</h1><p>仓库本质上就是一个文件夹，一个目录，一个项目。</p>
<h2 id="创建方法1"><a href="#创建方法1" class="headerlink" title="创建方法1"></a>创建方法1</h2><p>比如打开一个目录，输入<code>git init</code></p>
<p><img src="/2018/02/01/git学习/2.jpg" alt="init"></p>
<p>可以看到初始化了一个空的git仓库。</p>
<p>然后切换到bash 输入<code>ls -la</code>酒吧当前目录下的所有的子目录列出来:</p>
<p><img src="/2018/02/01/git学习/7.jpg" alt="列出目录"></p>
<p>可以看到<code>.git</code>被列出来，它是个隐藏文件夹。</p>
<p>这时候 test1 就已经是一个仓库了。</p>
<h2 id="创建方法2"><a href="#创建方法2" class="headerlink" title="创建方法2"></a>创建方法2</h2><p>或者进入到根目录,如输入<code>cd ..</code>,然后输入 <code>git init test2</code>。</p>
<p><img src="/2018/02/01/git学习/8.jpg" alt="init test2"></p>
<p><img src="/2018/02/01/git学习/9.jpg" alt="test2"></p>
<p>可以看到一样成功创建了tes2文件夹和其中的.git隐藏文件夹，和上面的创建方法是一样的。</p>
<h2 id="从远程clone一个仓库"><a href="#从远程clone一个仓库" class="headerlink" title="从远程clone一个仓库"></a>从远程clone一个仓库</h2><p>比如在github上找到一个文件仓库，比如找到vue的github仓库<br><img src="/2018/02/01/git学习/10.jpg" alt="vue地址"></p>
<p>输入<code>git clone https://github.com/vuejs/vue.git</code>回车</p>
<p><img src="/2018/02/01/git学习/11.jpg" alt="clone"></p>
<p><img src="/2018/02/01/git学习/12.jpg" alt="vue克隆成功"><br>可以看到正在clone。可以看到目录下多了<code>vue</code>文件夹，这就是从远程克隆的仓库。或者在输入clone命令时后面加个自己想要命名的文件夹名，这样下载下来就是以这个文件夹命名的，比如<code>git clone https://github.com/vuejs/vue.git test3</code>.可以自己试一下（可以换一个小一点的仓库克隆，这个我clone了好久 Orz）</p>
<h1 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a>基本用法</h1><h2 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h2><p><code>git status</code>是指查看仓库状态。</p>
<p><img src="/2018/02/01/git学习/13.jpg" alt="git status"></p>
<p>因为test1是一个空文件夹 所以显示上图的状态。</p>
<h2 id="commit"><a href="#commit" class="headerlink" title="commit"></a>commit</h2><p><code>commit</code>的意思是提交，可以把它看做历史节点,而上图的提示是No commits yet，这就是说没有一条历史记录，因为我们创建了后还没有进行提交。 </p>
<h2 id="Untracked-files"><a href="#Untracked-files" class="headerlink" title="Untracked files"></a>Untracked files</h2><p>如果我们新建一个文件，如test.txt,这时候执行<code>git status</code>命令，可以看到:<br><img src="/2018/02/01/git学习/14.jpg" alt="git status"><br><code>Untracked files</code>是指未跟踪的文件，也就是更改了文件还没有进行创建节点，即丢失后无法找回。</p>
<p>在VS Code的git工具中也可以看到修改的状态为未跟踪的。<br><img src="/2018/02/01/git学习/15.jpg" alt=""></p>
<h2 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h2><p><code>git add .</code>将所有的修改添加到暂存区</p>
<p>如上，我们创建了一个test.txt,输入<code>git add .</code>回车,然后输入<code>git status</code>查看现在的状态。</p>
<p><img src="/2018/02/01/git学习/17.jpg" alt=""></p>
<p>可以看到vs code中的git工具也发生了变化：</p>
<p><img src="/2018/02/01/git学习/16.jpg" alt=""></p>
<h2 id="git-commit-m-“描述”"><a href="#git-commit-m-“描述”" class="headerlink" title="git commit -m “描述”"></a>git commit -m “描述”</h2><p><code>git commit -m &quot;描述&quot;</code>提交版本</p>
<p><img src="/2018/02/01/git学习/18.jpg" alt="提交更改"></p>
<p>输入命令后，可以看到 nothing to commit,working tree clean，也就是所有的更改都保存了。</p>
<h2 id="git-log"><a href="#git-log" class="headerlink" title="git log"></a>git log</h2><p><code>git log</code>查看版本记录<br>可以查看所有的更改记录</p>
<p><img src="/2018/02/01/git学习/19.jpg" alt="更改记录"></p>
<p>这里只有一条更改记录。</p>
<p>而上面的commit 后面的一串字符就是上次更改的记录码。</p>
<p>我们这时候更改一下test.txt，保存。</p>
<p><img src="/2018/02/01/git学习/20.jpg" alt="更改"></p>
<p>这时候文件内容发生了变化，在进行一次提交操作</p>
<p><img src="/2018/02/01/git学习/21.jpg" alt="提交"></p>
<p>这时候再看记录，有两条记录：</p>
<p><img src="/2018/02/01/git学习/22.jpg" alt="记录"></p>
<h2 id="git-checkout-xxx"><a href="#git-checkout-xxx" class="headerlink" title="git checkout xxx"></a>git checkout xxx</h2><p><code>git checkout xxx</code>——穿越到指定的历史节点，也就是前面commit的节点。可以看描述选择退回到哪个节点，这也反映了写描述的重要性。</p>
<p>xxx是指上面<code>git log</code>查看时commit后面的码，复制前七位就可以定位，当然也可以复制多于七位。</p>
<p><img src="/2018/02/01/git学习/23.jpg" alt="查看历史版本"></p>
<p>可以看到文件变了：<br><img src="/2018/02/01/git学习/24.jpg" alt="文件变了"></p>
<h1 id="三种状态"><a href="#三种状态" class="headerlink" title="三种状态"></a>三种状态</h1><p>上面时回到了第一个节点，现在回到第二个节点。<br>输入<code>git checkout 1529b8c93ec</code>，确认退回成功。</p>
<p>从上面可以看出，执行任何一个commit操作都要执行三步：<br><code>modified(已修改)</code> -&gt; <code>staged(已暂存)</code> -&gt; <code>committed</code></p>
<p>staged 状态可以看到即将提交的文件，比如如果想只提交<code>test.txt</code>文件，可以在<code>git add .</code>的时候输入<code>git add test.txt</code>。<br>另外 <code>git log</code>只能查看提交的内容和描述，并不能看其中哪些内容修改了，使用<code>git log -p</code>可以查看具体修改了哪些内容.</p>
<p><img src="/2018/02/01/git学习/25.jpg" alt="具体内容"></p>
<p>可以看到+后面的就是修改的内容。</p>
<p>commit的内容是添加到staged暂存区中的内容，比如在<code>git add .</code>后又进行了修改但是没有再次执行<code>git add .</code>命令，那么commit的时候就是暂存区中的内容而不包括最新修改的内容。</p>
<h1 id="标签tag"><a href="#标签tag" class="headerlink" title="标签tag"></a>标签tag</h1><p>如果在项目中要很经常的进行修改，那么会产生很多个节点，但是会有一些节点非常重要，那么可以给这些关键的重要节点打一个标签。比如完成了代码的v1.0版本，后面又有了v2.0版本，中间的v1.1,v1.x并不重要，那么这些大版本就是重要节点。</p>
<p>输入<code>git add . &amp;&amp; git commit -m &quot;v2.0&quot;</code>可以执行两条命令。</p>
<p><code>git log --oneline</code>可以查看简写的版本</p>
<p><img src="/2018/02/01/git学习/26.jpg" alt="oneline"></p>
<p>那么可以给v2.0打一个标签,用法：<code>git tag -a 标签名 -m &quot;备注&quot;</code>，用它进行附注标签。这种方法是给最近的一个节点加标签。</p>
<p>这时候输入<code>git tag</code>可以看到tag的信息。</p>
<p><img src="/2018/02/01/git学习/27.jpg" alt="tag"></p>
<p>如果想给某个节点加标签，则可以用<code>git tag -a 标签名 -m &quot;备注&quot; 版本码</code></p>
<p><img src="/2018/02/01/git学习/28.jpg" alt="tag"><br>可以看到添加成功了（上面的v2.0加错了加了两个标签 orz）</p>
<p><code>git show 标签名</code>：查看某个标签的详细信息</p>
<p><code>git checkout 标签名</code>可以直接回溯到标签所在的提交，这样比使用版本码要方便</p>
<p>在回溯到历史版本后 输入<code>git log --oneline --all</code>可以查看所有的节点</p>
<h1 id="分支-branch"><a href="#分支-branch" class="headerlink" title="分支 branch"></a>分支 branch</h1><p>指在时间的维度上可以有多线，及时间一样的基础上进行其他的修改。主线为master时可以给分支命名其他的名。</p>
<p>比如这里在test2目录下新建b.txt。<br>输入两行内容后分别commit。</p>
<p><img src="/2018/02/01/git学习/30.jpg" alt=""></p>
<p>现在的mater分支上有两个版本：</p>
<p><img src="/2018/02/01/git学习/29.jpg" alt=""></p>
<p>给文本添加第三行并且执行<code>git add .</code> 和<code>git commit -m &quot;&quot;</code>操作。</p>
<p>然后<code>git branch 分支名</code>创建分支,然后<code>git checkout 分支名</code>切换到分支。<br><img src="/2018/02/01/git学习/31.jpg" alt="3"></p>
<p><img src="/2018/02/01/git学习/32.jpg" alt="切换到分支"></p>
<p>可以看到切换到了分支notmaster。</p>
<p>这时候修改b.txt的内容，<br>然后执行<code>git add .</code> 和<code>git commit -m &quot;&quot;</code>操作</p>
<p><img src="/2018/02/01/git学习/33.jpg" alt="修改内容"></p>
<p><img src="/2018/02/01/git学习/34.jpg" alt="commit"></p>
<p>然后<code>git log --oneline</code>可以看到多了的记录是在分支上的</p>
<p><img src="/2018/02/01/git学习/35.jpg" alt="commit"></p>
<p>这时候在分支后面的提交就是在分支上了。</p>
<p>现在如果切换到mater-&gt;<code>git checkout master</code>，可以看到内容变回刚才的节点(即刚才创建分支的时候的节点)：</p>
<p><img src="/2018/02/01/git学习/36.jpg" alt="master"></p>
<p>这时候再添加一行然后执行commit操作,可以看到:<br><img src="/2018/02/01/git学习/37.jpg" alt="git log"></p>
<p>或者<code>git log --all --graph</code>图示全部历史记录。</p>
<p><code>git checkout -b 分支</code>，创建并切换到分支。</p>
<p>分支的功能在做项目的时候可以经常用到，比如在1-&gt;2的时候没有bug，但是在2-&gt;3的时候发现有bug,这时候可以在2创建一个分支，专门在分支进行修改bug,且在master可以继续进行开发。在最后的第二版开发完成后，把分支的修改bug版本进行合并，这样就修改了bug也推进了项目。</p>
<h1 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a>合并分支</h1><p>上面讲到,在修改bug的同时可以进行项目的推进，但是在完成了bug的修改和第二版的项目后，要将两者合并，实现“完全体”,这就需要合并分支。</p>
<p>现在回到branch，</p>
<p><img src="/2018/02/01/git学习/38.jpg" alt="branch"></p>
<p>可以看到HEAD所在的就是当前的节点和分支。在分支上修改了代码进行commit</p>
<p><img src="/2018/02/01/git学习/39.jpg" alt="修改"></p>
<p>现在虽然创建了分支并且更新了内容，但是还没有和master主分支合并</p>
<h2 id="git-merge-分支名合并分支"><a href="#git-merge-分支名合并分支" class="headerlink" title="git merge 分支名合并分支"></a><code>git merge 分支名</code>合并分支</h2><p><img src="/2018/02/01/git学习/40.jpg" alt="合并"></p>
<p><img src="/2018/02/01/git学习/41.jpg" alt="合并-2"></p>
<p>可以看到 CONFLICT提示内容有冲突，在第三行开始冲突，所以git不知道该如何处理。</p>
<p>这时候可以在文件中进行更改，然后再进行commit操作。然后这样就合并了两个分支。</p>
<p>这时候可以输入命令查看，通过图解可以看到很清楚的解释了刚才的合并操作。</p>
<p><img src="/2018/02/01/git学习/42.jpg" alt="查看"></p>
<h1 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h1><p>我们可以将本机上的仓库内容存放在远程仓库（如github 和 码云或者远程的另一台电脑或服务器）</p>
<p>即<code>local</code> -&gt; <code>server</code> -&gt; <code>loacl</code></p>
<p>比如在commit了一个版本后，推送到服务器上时，我们用github。</p>
<p>在github新建一个仓库，<code>Create a new repository</code>,创建成功后，可以看到仓库的地址。<br>那么接下来在本地指定远程仓库的地址。</p>
<h2 id="git-remote-add-远程名称-远程地址-添加远程仓库"><a href="#git-remote-add-远程名称-远程地址-添加远程仓库" class="headerlink" title="git remote add 远程名称 远程地址 添加远程仓库"></a><code>git remote add 远程名称 远程地址</code> 添加远程仓库</h2><p>然后<code>git remote</code>可以列出所有远程仓库</p>
<p><code>git remote -v</code>可以列出所有远程仓库和详细信息</p>
<p><img src="/2018/02/01/git学习/43.jpg" alt="远程仓库"></p>
<p>顾名思义,fetch是下载地址,push是上传地址。</p>
<h2 id="git-push-u-远程名-分支名上传代码"><a href="#git-push-u-远程名-分支名上传代码" class="headerlink" title="git push -u 远程名 分支名上传代码"></a><code>git push -u 远程名 分支名</code>上传代码</h2><p>加-u的意思是在服务器端设置，如果有人想下载代码的时候，应该往那个分支上合并,所以要记得加-u.</p>
<p><img src="/2018/02/01/git学习/44.jpg" alt="push成功"></p>
<p>刷新仓库可以看到推送成功：</p>
<p><img src="/2018/02/01/git学习/45.jpg" alt="push成功"></p>
<p>在进行了修改添加后，可以同样执行这个操作。</p>
<h2 id="git-clone-仓库地址从远端克隆仓库到本地"><a href="#git-clone-仓库地址从远端克隆仓库到本地" class="headerlink" title="git clone 仓库地址从远端克隆仓库到本地"></a><code>git clone 仓库地址</code>从远端克隆仓库到本地</h2><p>进入到刚克隆的仓库，输入<code>git log</code>同样可以看到操作的历史</p>
<p>这时候从远端克隆下的分支默认名为origin，他只是一个分支的名字，和master等没有本质区别</p>
<p>这时候在这个目录下进行了修改再推送时，要在<code>git push -u 远程名 master</code>这里将远程名改为现在的远程名，可以用<code>git remote</code>查看远程名，如果还用github进行推送会报错。</p>
<p><img src="/2018/02/01/git学习/46.jpg" alt="远程名为origin"></p>
<p><img src="/2018/02/01/git学习/47.jpg" alt="如果用github会报错"></p>
<p><img src="/2018/02/01/git学习/48.jpg" alt="改为origin成功"></p>
<h1 id="多人远程合作"><a href="#多人远程合作" class="headerlink" title="多人远程合作"></a>多人远程合作</h1><h2 id="git-pull获取远程更新"><a href="#git-pull获取远程更新" class="headerlink" title="git pull获取远程更新"></a><code>git pull</code>获取远程更新</h2><p>现在模拟A和B是两台电脑，他们都从仓库clone了项目，A进行了修改，通过<code>git push -u origin master</code>更新了项目，B使用<code>git pull</code>。即通过<code>git push -u origin master</code>和<code>git pull</code>进行推送和拉取。但是如果A先推送了一个版本，B不知情的情况下对某一行也进行了修改,这时候如果提交，会显示冲突的错误，这时就知道要先<code>git pull</code>一份服务器端的代码，这时候在本地可以看出来冲突的对比，<code>=</code>等号的上面和下面会显示冲突的内容对比,然后对冲突的代码进行整合后，在进行push操作。</p>
<p>其实<code>git pull</code> 相当于<code>git fetch &amp;&amp; git merge</code>即下载和合并,放在已提交的阶段</p>
<p>详情参见表严肃的速查表 <a href="http://biaoyansu.com/27.cheatsheet" target="_blank" rel="external">http://biaoyansu.com/27.cheatsheet</a></p>
<p>完 </p>
<p>根据 表严肃的课程整理书写，地址<a href="http://biaoyansu.com/i/6593023230131" target="_blank" rel="external">http://biaoyansu.com/i/6593023230131</a> </p>
]]></content>
      
        <categories>
            
            <category> 学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[webpack的简单应用(entry 和 output)]]></title>
      <url>/2018/01/31/webpack%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8-entry-%E5%92%8C-output/</url>
      <content type="html"><![CDATA[<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/webpack-view.jpg" alt="webpack"><br><a id="more"></a></p>
<p>在简单配置了webpack后，指定了它的入口和出口，即entry和output。但是在业务逻辑比较复杂的时候，页面不只有一页。<br>比如 有一个index.html页和signup.html注册页。<br><code>index.html</code>引用了<code>base.js</code> 和 <code>home.js</code>,<code>signup.html</code>引用了<code>base.js</code>和<code>signup.js</code>。<br><img src="/2018/01/31/webpack的简单应用-entry-和-output/1.png" alt="index.html"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/2.png" alt="signup.html"><br>即项目中如果有很多页，而且会有相同的依赖（比如这里的base.js），也有不同的js控制着各个不同的页面的业务逻辑。</p>
<p>这时候在<code>webpack.config.js</code>中将entry设置为一个入口对象，同时出口也变了，他会根据不同的入口文件生成不同的出口文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">module.exports=&#123;</div><div class="line">	entry:&#123;</div><div class="line">		home:&apos;./js/home.js&apos;,</div><div class="line">		signup:&apos;./js/signup.js &apos;</div><div class="line">&#125;,</div><div class="line">output:&#123;</div><div class="line">        filename:&apos;[name].bundle.js&apos;, //这里的文件名是动态生成的，name即是entry中的键名</div><div class="line">        path:__dirname+&apos;/dist&apos;       //目录生成，如果没有dist文件夹则会自动创建这个文件夹，将上面的文件生成保存在这个目录</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在相应目录下创建这三个js文件：</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/3.png" alt="js"></p>
<p>这时候在index.html和signup.html中就不再需要引用base.js了。</p>
<p>这时只需要引用webpack打包后的动态生成的[name].bundle.js文件即可：</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/4.png" alt="index.html"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/5.png" alt="signup.html"></p>
<p>假设base.js是整个网站的依赖（因为刚开始两个html也都引用了这个文件），这里面一般会存放一些重要的配置项。</p>
<p>下面举例：</p>
<h3 id="非ES6写法"><a href="#非ES6写法" class="headerlink" title="非ES6写法"></a>非ES6写法</h3><p><img src="/2018/01/31/webpack的简单应用-entry-和-output/6.png" alt="base.js"></p>
<p>open 决定网站是否是开放注册的，这时候通过module.exports将open传出去。<br>home.js 和 signup.js 接收open参数值：</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/7.png" alt="home.js"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/8.png" alt="signup.js"></p>
<p>执行<code>npm run pack</code>命令</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/9.png" alt="result"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/10.png" alt="result"></p>
<p>这时候可以看到生成成功。</p>
<p>这时候打开index.html。可以看到<br><img src="/2018/01/31/webpack的简单应用-entry-和-output/11.png" alt="result"></p>
<p>页面生成成功，点击注册连接时，跳转到指定页面并且显示指定内容</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/12.png" alt="result"></p>
<p>如果把open 的值改为false。即open = false重新执行<code>npm run pack</code>命令，刷新可以看到：</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/13.png" alt="result"></p>
<p> 并且点击到index.html时，没有显示任何内容，这和我们在home.js中设置的结果是一样的。</p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/14.png" alt="result"></p>
<p>一般类似于这种多页的应用，一般都会给每一页一个打包的地址，具体每一页的入口文件用到了哪些依赖我们不用管，只需交给webpack去处理即可。另外这种写法是node的写法，可以用ES6的写法更简单快捷。</p>
<h3 id="ES6写法"><a href="#ES6写法" class="headerlink" title="ES6写法"></a>ES6写法</h3><p><img src="/2018/01/31/webpack的简单应用-entry-和-output/15.png" alt="base.js"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/16.png" alt="signup.js"></p>
<p><img src="/2018/01/31/webpack的简单应用-entry-和-output/17.png" alt="home.js"><br>这里open可以直接解构出来，在下面可以直接用，即不需要再var open=base.open，它直接知道from导进来的东西是个对象，而且把对象中的一个键（这里是open）变成了一个变量，可以直接在后面使用。<br>这时候重新npm run pack生成，结果是一样的。</p>
<p>webpack中的多入口和多出口。完</p>
<p>根据表严肃<a href="http://biaoyansu.com/i/6593023230131" target="_blank" rel="external">http://biaoyansu.com/i/6593023230131</a>  的视频总结。</p>
]]></content>
      
        <categories>
            
            <category> 学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> webpack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[webpack的安装配置]]></title>
      <url>/2018/01/31/webpack%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</url>
      <content type="html"><![CDATA[<p><img src="/2018/01/31/webpack的安装配置/webpack-view.jpg" alt="webpack"><br><a id="more"></a></p>
<h1 id="1-确保安装node和webpack"><a href="#1-确保安装node和webpack" class="headerlink" title="1.确保安装node和webpack"></a>1.确保安装node和webpack</h1><p>node:</p>
<p><img src="/2018/01/31/webpack的安装配置/node.png" alt="node"></p>
<p>webpack:</p>
<p><img src="/2018/01/31/webpack的安装配置/webpack.png" alt="webpack"></p>
<p>如果没有版本号则代表没有安装</p>
<p>首先你需要安装一个全局的webpack</p>
<p>执行 <code>pm install webpack -g</code></p>
<p>这样你才可以正确的使用webpack这个命令</p>
<p>推荐在当前项目里面也安装一个webpack, 这样就不用担心更换了电脑或者其他人使用时因为版本的不同而会导致错误</p>
<p>这样就可以在你的webpack.config.js里面方便的引用webpack</p>
<h1 id="2-在当前项目安装webpack"><a href="#2-在当前项目安装webpack" class="headerlink" title="2.在当前项目安装webpack"></a>2.在当前项目安装webpack</h1><h2 id="在当前目录生成package-json文件"><a href="#在当前目录生成package-json文件" class="headerlink" title="在当前目录生成package.json文件"></a>在当前目录生成package.json文件</h2><p>输入<code>npm init -y</code> 生成<code>package.json</code>文件</p>
<p><img src="/2018/01/31/webpack的安装配置/package.json.png" alt="package.json"><br><img src="/2018/01/31/webpack的安装配置/package.json-1.png" alt="package.json-m"></p>
<p>生成了package.json,npm就会认为整个目录是一个模块了。</p>
<h2 id="在当前目录安装webpack"><a href="#在当前目录安装webpack" class="headerlink" title="在当前目录安装webpack"></a>在当前目录安装webpack</h2><p>执行<code>npm install webpack --save-dev</code></p>
<p><img src="/2018/01/31/webpack的安装配置/install-webpack.png" alt="安装webpack"></p>
<p><img src="/2018/01/31/webpack的安装配置/success-webpack.png" alt="安装成功提示"></p>
<p>这里的WARN只是警告可以不用管</p>
<p>可以看到安装成功</p>
<p><img src="/2018/01/31/webpack的安装配置/success-webpack-1.png" alt="目录webpack"></p>
<p>这时候package.json里面就有了webpack 和它的版本号：</p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-2.png" alt="package.json-v"></p>
<h1 id="3-使用"><a href="#3-使用" class="headerlink" title="3.使用"></a>3.使用</h1><p>这时候可以直接用此目录下的webpack指令来执行操作：</p>
<p><code>node_modules/.bin/webpack a.js bundle.js</code></p>
<p>但是这个路径很长，输入并不方便，可以在package.json里面进行配置，然后直接调用命令即可。</p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-3.png" alt="package.json配置"></p>
<p>pack和后面的字符串就是键值对的形式，pack即自定义的命令的名称，值就是上面的很长的命令。保存后执行<code>npm run pack</code></p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-result.png" alt="执行命令"></p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-result-1.png" alt="执行命令结果"></p>
<p>可以看到这种方法仍然是生成成功的。</p>
<h1 id="4-webpack-config-js"><a href="#4-webpack-config-js" class="headerlink" title="4.webpack.config.js"></a>4.webpack.config.js</h1><p>这个js文件顾名思义可以配置webpack。<br>基本写法是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">module.exports=&#123;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在这里面可以传一些东西出去。<br>比如 :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">module.exports=&#123;</div><div class="line">entry: &apos;../a&apos; //入口文件</div><div class="line">output: &#123;</div><div class="line">	filename:&apos;bundle.js&apos;,  //文件名</div><div class="line">	path:__dirname //__dirname是node里面一个特殊的变量，它会被node解释为当前的文件所在的目录</div><div class="line">&#125;    //输出文件</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><img src="/2018/01/31/webpack的安装配置/webpack.config.js.png" alt="配置文件"></p>
<p>那么有了这两个设置参数，可以将package.json文件里面的<br><code>&quot;pack&quot;:&quot;node_modules/.bin/webpack a.js bundle.js&quot;</code>中的<code>a.js</code> 和 <code>bundel.js</code></p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-4.jpg" alt="配置文件"></p>
<p>保存后,直接 <code>npm run pack</code>，执行结果也是成功的：</p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-result-2.png" alt="配置文件结果"></p>
<p><img src="/2018/01/31/webpack的安装配置/package.json-result-3.png" alt="配置文件结果"></p>
<p>完。</p>
<p>根据表严肃的视频总结，地址：<a href="http://biaoyansu.com/i/6593023230131" target="_blank" rel="external">http://biaoyansu.com/i/6593023230131</a></p>
]]></content>
      
        <categories>
            
            <category> 学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> webpack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[WEBAPI解决跨域问题]]></title>
      <url>/2017/12/27/WEBAPI%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<p><img src="/2017/12/27/WEBAPI解决跨域问题/WebApiConfig%E4%B8%AD%E9%85%8D%E7%BD%AE.jpg" alt="WebApiConfig" title="WebApiConfig中配置"><br>在WEBAPI的工程中，解决跨域问题有很多方法，这里介绍在服务端配置的方法。<br><a id="more"></a><br>在WEBAPI的工程中，解决跨域问题有很多方法，这里介绍在服务端配置的方法。</p>
<h1 id="添加引用"><a href="#添加引用" class="headerlink" title="添加引用"></a>添加引用</h1><p>首先添加 <code>System.Web.cors.dll</code> 和 <code>System.Web.Http.cors.dll</code>。</p>
<p><img src="/2017/12/27/WEBAPI解决跨域问题/System.Web.Http.Cors.jpg" alt="System.Web.Http.cors.dll" title="System.Web.Http.Cors"></p>
<p><img src="/2017/12/27/WEBAPI解决跨域问题/System.Web.cors.jpg" alt="System.Web.cors.dll" title="System.Web.Cors"></p>
<h1 id="Web-Conefig配置"><a href="#Web-Conefig配置" class="headerlink" title="Web.Conefig配置"></a>Web.Conefig配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;appSettings&gt;</div><div class="line">   &lt;add key=&quot;cors_allowOrigins&quot; value=&quot;*&quot;/&gt;</div><div class="line">   &lt;add key=&quot;cors_allowHeaders&quot; value=&quot;*&quot;/&gt;</div><div class="line">   &lt;add key=&quot;cors_allowMethods&quot; value=&quot;*&quot;/&gt;</div><div class="line"> &lt;/appSettings&gt;</div></pre></td></tr></table></figure>
<p>  <code>*</code> 代表允许所有</p>
<p><img src="/2017/12/27/WEBAPI解决跨域问题/Web.config.jpg" alt="Web.config" title="Web.config"></p>
<h1 id="WebApiConfig配置"><a href="#WebApiConfig配置" class="headerlink" title="WebApiConfig配置"></a>WebApiConfig配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">  //解决API跨域访问的问题</div><div class="line">var allowOrigins = ConfigurationManager.AppSettings[&quot;cors_allowOrigins&quot;];</div><div class="line">var allowHeaders = ConfigurationManager.AppSettings[&quot;cors_allowHeaders&quot;];</div><div class="line">var allowMethods = ConfigurationManager.AppSettings[&quot;cors_allowMethods&quot;];</div><div class="line">var globalCors = new EnableCorsAttribute(allowOrigins, allowHeaders, allowMethods) &#123; SupportsCredentials = true &#125;;</div><div class="line">config.EnableCors(globalCors);</div></pre></td></tr></table></figure>
<p><img src="/2017/12/27/WEBAPI解决跨域问题/WebApiConfig%E4%B8%AD%E9%85%8D%E7%BD%AE.jpg" alt="WebApiConfig" title="WebApiConfig中配置"></p>
<p>完。</p>
]]></content>
      
        
        <tags>
            
            <tag> WEBAPI </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql学习小记系列（持续更新）]]></title>
      <url>/2017/12/11/mysql%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0%E7%B3%BB%E5%88%97%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
      <content type="html"><![CDATA[<p> 以下环境为mysql+Navicat Premium</p>
<h1 id="在mysql中使用UUID"><a href="#在mysql中使用UUID" class="headerlink" title="在mysql中使用UUID"></a>在mysql中使用UUID</h1><p>效果如下：</p>
<p><img src="/2017/12/11/mysql学习小记系列（持续更新）/UUID.jpg" alt="UUID"></p>
<p>SQL语句有函数生成guid:UUID()，一般使用CHAR(36)或者BINARY(36)来存储uuid</p>
<p>例如sql语句为：INSERT INTO USERS(UUID) VALUES (UUID())</p>
<h1 id="mysql中写入时间"><a href="#mysql中写入时间" class="headerlink" title="mysql中写入时间"></a>mysql中写入时间</h1><p>  DATETIME 类型可用于需要同时包含日期和时间信息的值。MySQL 以 ‘YYYY-MM-DD HH:MM:SS’ 格式检索与显示 DATETIME 类型。支持的范围是 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’。</p>
<p>  DATE 类型可用于需要一个日期值而不需要时间部分时。MySQL 以 ‘YYYY-MM-DD’ 格式检索与显示DATE 值。支持的范围是 ‘1000-01-01’ 到 ‘9999-12-31’。</p>
<p>  TIMESTAMP 列类型提供了一种类型，通过它你可以以当前操作的日期和时间自动地标记 Insert或Update 操作。如果一张表中有多个 TIMESTAMP 列，只有第一个被自动更新。</p>
<p>  目前我在项目中使用了DATETIME和DATE类型。</p>
<p>  例如DATETIME类型的数据在数据库中如下：</p>
<p>  <img src="/2017/12/11/mysql学习小记系列（持续更新）/DATETIME.jpg" alt="DATETIME"></p>
<p>  在写入数据库中的时候，用了NOW()函数，让数据库自动写入当前系统时间，对应SQL语句如下：INSERT INTO USER(CREATEDATE)  VALUES(now())</p>
<p>  DATE类型的数据在数据库中如下：</p>
<p>   <img src="/2017/12/11/mysql学习小记系列（持续更新）/DATE.jpg" alt="DATE"></p>
<p>  这条数据在应用中是通过前台传字符串，后台转为DATE格式的。例如前台传来的字符串为”2017-11-21”，用<code>STR_TO_DATE(&#39;2017-11-21&#39;,&#39;%Y-%m-%d&#39;)</code>来转换，当然也可以转换DATETIME格式的日期。</p>
<p>  目前项目中还没有使用TIMESTAMP数据类型。暂时不予详细展开。</p>
]]></content>
      
        <categories>
            
            <category> 学习 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysql </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[C#操作mysql数据库执行SqlDataReader.Read后使用另一个SQLCommand执行Insert操作出现错误的解决办法]]></title>
      <url>/2017/12/03/C-%E6%93%8D%E4%BD%9Cmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%A7%E8%A1%8CSqlDataReader-Read%E5%90%8E%E4%BD%BF%E7%94%A8%E5%8F%A6%E4%B8%80%E4%B8%AASQLCommand%E6%89%A7%E8%A1%8CInsert%E6%93%8D%E4%BD%9C%E5%87%BA%E7%8E%B0%E9%94%99%E8%AF%AF%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>今天在写WEBAPI的时候，进行用户注册的编写，发生了如下错误：</p>
<p><img src="/2017/12/03/C-操作mysql数据库执行SqlDataReader-Read后使用另一个SQLCommand执行Insert操作出现错误的解决办法/错误1.jpg" alt="错误"></p>
<p>   后来确定了发生错误的原因是执行SqlDataReader.Read之后，如果还想用另一个SqlCommand执行Insert或者Update操作的话，会得到一个错误提示：There is already an open DataReader associated with this Command which must be closed first.，然后一般就会产生数据保存失败的异常。</p>
<p>   注册用户的代码如下：<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"> public string RegisterUser(string uname,string upwd,string email,string mobile,string confirmpassword)</div><div class="line">        &#123;</div><div class="line">            MySqlConnection mysql = getMySqlConnection();</div><div class="line">            mysql.Open();</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                if (uname == null || email == null || upwd == null || mobile == null || confirmpassword == null)</div><div class="line">                &#123;</div><div class="line">                    return &quot;请完善信息&quot;;</div><div class="line">                &#125;</div><div class="line">                if (!String.Equals(upwd, confirmpassword))</div><div class="line">                &#123;</div><div class="line">                    return &quot;两次输入密码不一致！&quot;;</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                string CheckUser = &quot;Select * from name where username=&apos;&quot; + uname + &quot;&apos;&quot;;</div><div class="line">                MySqlCommand mySqlCommand = getSqlCommand(CheckUser, mysql);</div><div class="line">                MySqlDataReader reader = mySqlCommand.ExecuteReader();</div><div class="line">                if (reader.Read())</div><div class="line">                &#123;</div><div class="line">                    return &quot;用户已存在&quot;;</div><div class="line">                &#125;</div><div class="line">                else </div><div class="line">                &#123;              </div><div class="line">                string AddUser = @&quot;Insert into name(username,pword,email,mobile)Values(&apos;&quot; + uname + &quot;&apos;,&apos;&quot; + upwd + &quot;&apos;,&apos;&quot; + email + &quot;&apos;,&apos;&quot; + mobile + &quot;&apos;)&quot;;</div><div class="line">                MySqlCommand insertuser = new MySqlCommand(AddUser, mysql);</div><div class="line">                if (insertuser.ExecuteNonQuery() &gt; 0)</div><div class="line">                &#123; return &quot;注册成功！&quot;; &#125;</div><div class="line">                else &#123; return &quot;注册失败！&quot;; &#125;</div><div class="line">                &#125;</div><div class="line">     &#125;</div><div class="line">            catch</div><div class="line">            &#123;</div><div class="line">               return &quot;错误&quot;;</div><div class="line">            &#125;</div><div class="line">            finally</div><div class="line">            &#123;</div><div class="line">               mysql.Close();</div><div class="line">            &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>   在知道了报错原因后，在网上搜了两种方法：<br>   1.不要用共用一个connection,用完就释放，所以在下面先把connection关闭再连接，测试可行。<br>   <img src="/2017/12/03/C-操作mysql数据库执行SqlDataReader-Read后使用另一个SQLCommand执行Insert操作出现错误的解决办法/成功1.jpg" alt="成功1"></p>
<p>   2.关闭当前的reader方法。然后继续执行代码 ，可行。<br>    <img src="/2017/12/03/C-操作mysql数据库执行SqlDataReader-Read后使用另一个SQLCommand执行Insert操作出现错误的解决办法/成功2.png" alt="成功2"></p>
<p>暂时是用这两种方法解决了问题，以后有更好的方法再补充。</p>
]]></content>
      
        <categories>
            
            <category> 项目 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> C# </tag>
            
            <tag> 遇到的坑 </tag>
            
            <tag> mysql </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[C#将多个文件打包成.zip文件]]></title>
      <url>/2017/10/30/C-%E5%B0%86%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6%E6%89%93%E5%8C%85%E6%88%90-zip%E6%96%87%E4%BB%B6/</url>
      <content type="html"><![CDATA[<p>近几天的项目作业过程中，遇到了需要一键下载多个文件的需求，于是想采取在后台将需要一键下载的文件打包成压缩文件，然后进行下载的方式。</p>
<p>在.net4.5中可以使用调用winrar命令的方式来直接进行生成压缩文件。但是在这里我采用引入ICSharpCode.SharpZipLib.dll的方法，（官方下载地址：<a href="http://www.icsharpcode.net/opensource/sharpziplib/" target="_blank" rel="external">http://www.icsharpcode.net/opensource/sharpziplib/</a>  ） 用这个程序集将windows文件进行打包。</p>
<p>首先，将打包的方法封装在一个类中，然后在一般应用程序.ashx文件中调用相应的方法。因为在项目中只需要进行打包文件，所以这里只写一下压缩文件的代码，解压缩的方法应该类似，我没有试过。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.Linq;</div><div class="line">using System.IO;</div><div class="line">using ICSharpCode.SharpZipLib.Zip;</div><div class="line">using ICSharpCode.SharpZipLib.Checksums;</div><div class="line">using System.Diagnostics;</div><div class="line">using Microsoft.Win32;</div><div class="line"></div><div class="line">namespace ZipCommon</div><div class="line">&#123;</div><div class="line">    public class ZipHelper</div><div class="line">    &#123;</div><div class="line"></div><div class="line">        #region 压缩多个文件</div><div class="line"></div><div class="line">        /// &lt;summary&gt;  </div><div class="line">        ///  压缩多个文件  </div><div class="line">        /// &lt;/summary&gt;  </div><div class="line">        /// &lt;param name=&quot;files&quot;&gt;文件名&lt;/param&gt;  </div><div class="line">        /// &lt;param name=&quot;ZipedFileName&quot;&gt;压缩包文件名&lt;/param&gt;  </div><div class="line">        /// &lt;param name=&quot;Password&quot;&gt;解压码&lt;/param&gt;  </div><div class="line">        /// &lt;returns&gt;&lt;/returns&gt;  </div><div class="line">        public static void Zip1(string[] files, string ZipedFileName, string Password)</div><div class="line">        &#123;</div><div class="line">            files = files.Where(f =&gt; File.Exists(f)).ToArray();</div><div class="line">            if (files.Length == 0) throw new FileNotFoundException(&quot;未找到指定打包的文件&quot;);</div><div class="line">            ZipOutputStream s = new ZipOutputStream(File.Create(ZipedFileName));</div><div class="line">            s.SetLevel(6);</div><div class="line">            if (!string.IsNullOrEmpty(Password.Trim())) s.Password = Password.Trim();</div><div class="line">            ZipFileDictory(files, s);</div><div class="line">            s.Finish();</div><div class="line">            s.Close();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        /// &lt;summary&gt;  </div><div class="line">        ///  压缩多个文件  </div><div class="line">        /// &lt;/summary&gt;  </div><div class="line">        /// &lt;param name=&quot;files&quot;&gt;文件名&lt;/param&gt;  </div><div class="line">        /// &lt;param name=&quot;ZipedFileName&quot;&gt;压缩包文件名&lt;/param&gt;  </div><div class="line">        /// &lt;returns&gt;&lt;/returns&gt;  </div><div class="line">        public static void Zip(string[] files, string ZipedFileName)</div><div class="line">        &#123;</div><div class="line">            Zip1(files, ZipedFileName, string.Empty);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        public static void ZipFileDictory(string[] files, ZipOutputStream s)</div><div class="line">        &#123;</div><div class="line">            ZipEntry entry = null;</div><div class="line">            FileStream fs = null;</div><div class="line">            Crc32 crc = new Crc32();</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                //创建当前文件夹  </div><div class="line">                entry = new ZipEntry(&quot;/&quot;);  //加上 “/” 才会当成是文件夹创建  </div><div class="line"></div><div class="line">                s.PutNextEntry(entry);</div><div class="line">                s.Flush();</div><div class="line">                foreach (string file in files)</div><div class="line">                &#123;</div><div class="line">                    //打开压缩文件  </div><div class="line">                    fs = File.OpenRead(file);</div><div class="line">                    byte[] buffer = new byte[fs.Length];</div><div class="line">                    fs.Read(buffer, 0, buffer.Length);</div><div class="line">                    entry = new ZipEntry(&quot;/&quot; + Path.GetFileName(file));</div><div class="line">                    entry.DateTime = DateTime.Now;</div><div class="line">                    entry.Size = fs.Length;</div><div class="line">                    fs.Close();</div><div class="line">                    crc.Reset();</div><div class="line">                    crc.Update(buffer);</div><div class="line">                    entry.Crc = crc.Value;</div><div class="line">                    s.PutNextEntry(entry);</div><div class="line">                    s.Write(buffer, 0, buffer.Length);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            finally</div><div class="line">            &#123;</div><div class="line">                if (fs != null)</div><div class="line">                &#123;</div><div class="line">                    fs.Close();</div><div class="line">                    fs = null;</div><div class="line">                &#125;</div><div class="line">                if (entry != null)</div><div class="line">                    entry = null;</div><div class="line">                GC.Collect();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        #endregion 压缩多个文件</div><div class="line">		</div><div class="line">		&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>直接调用 ZipHelper.Zip（filepaths，zipedfilepath）即可。<br>注意： zipedfilepath的父级目录必须存在，否则在创建.zip文件时会报目录不存在的错误。这个坑我也遇到过。<br><img src="/2017/10/30/C-将多个文件打包成-zip文件/error1.jpg" alt="error"><br>还有一点要注意的是，这里的方法都是静态的，所以在调用方法时不需要进行实例化，只需写成 ZipHelper.Zip（filepaths，zipedfilepath） 这种形式就可以了。</p>
<p>在.ashx文件中的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"> #region 打包</div><div class="line">public void CreateZip(string WORD002,string WORD003,string WORD004,string WORD005,string WORD006,string WORD007)</div><div class="line">    &#123;</div><div class="line">        string[] files = new string[6];</div><div class="line">        files[0] = WORD002;</div><div class="line">        files[1] = WORD003;</div><div class="line">        files[2] = WORD004;</div><div class="line">        files[3] = WORD005;</div><div class="line">        files[4] = WORD006;</div><div class="line">        files[5] = WORD007;</div><div class="line">        ZIPFILEPATH = 绝对路径+文件名+ &quot;.zip&quot;;//这里要加上拓展名</div><div class="line">        ZipHelper.Zip(files,ZIPFILEPATH);</div><div class="line">    &#125;</div><div class="line">    #endregion</div></pre></td></tr></table></figure>
<p>这里的WORD002-007是要打包的文件的路径，将其存放在数组中，ZIPFILEPATH则是在服务器端要存放的打包文件的路径，需要绝对路径。</p>
<p>看一下需要打包的六个文件：<br><img src="/2017/10/30/C-将多个文件打包成-zip文件/文件.png" alt="文件"></p>
<p>生成ZIP文件成功：<br><img src="/2017/10/30/C-将多个文件打包成-zip文件/zip.jpg" alt="ZIP"></p>
<p>解压后的文件也可以正常打开：</p>
<p><img src="/2017/10/30/C-将多个文件打包成-zip文件/zip列表.jpg" alt="zip列表"></p>
<p>在实施过程中还遇到了一个坑，刚开始我的服务器上并没有安装winrar，而是安装了360压缩，导致在生成ZIP文件后，出现压缩错误的提示，在装了winrar并使用后，发现时正常的。</p>
<p>这时候只要把服务器上的zip路径传到前台，就可以下载了、</p>
]]></content>
      
        <categories>
            
            <category> 项目 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> C# </tag>
            
            <tag> 遇到的坑 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[通过C#向Word文档的表格中的任一行增加新行]]></title>
      <url>/2017/10/25/%E9%80%9A%E8%BF%87C-%E5%90%91Word%E6%96%87%E6%A1%A3%E7%9A%84%E8%A1%A8%E6%A0%BC%E4%B8%AD%E7%9A%84%E4%BB%BB%E4%B8%80%E8%A1%8C%E5%A2%9E%E5%8A%A0%E6%96%B0%E8%A1%8C/</url>
      <content type="html"><![CDATA[<p>今天在项目的作业过程中，遇到了需要通过C#操作Word模板向其中的表格添加内容。作业过程中发现，往往有的时候模板的表格的行数会多于或者少于所要写入的数据数量。而模板行数少于数据条数时会发生写入错误的提示，导致文档生成失败。因此需要根据需要写入的数据的数量来确定所需要的表格的数量，也就是能够动态的改变模板的表格的行数。在网上搜了一好久，发现很多给现有的表格添加一行的方法都是只能够在表格的最后一列添加，而项目需求的模板中需要动态改变添加行数的表格不在最前面也不在最后面，恰恰在中间。因此，搜了好久加上实验，终于找到了方法。在此做个记录。<br>    首先，说一下用C# .NET操作Word文档需要的引用：</p>
<p><img src="/2017/10/25/通过C-向Word文档的表格中的任一行增加新行/DLL.jpg" alt="DLL"></p>
<p>在新定义的类中添加头文件和书写代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using Microsoft.Office.Interop.Word;</div><div class="line"></div><div class="line">namespace WordDemo  //这边需要换成自己的命名空间名</div><div class="line">&#123;</div><div class="line">    public class Report</div><div class="line">    &#123;</div><div class="line">        private _Application wordApp = null;</div><div class="line">        private _Document wordDoc = null;</div><div class="line">        public _Application Application</div><div class="line">        &#123;</div><div class="line">            get</div><div class="line">            &#123;</div><div class="line">                return wordApp;</div><div class="line">            &#125;</div><div class="line">            set</div><div class="line">            &#123;</div><div class="line">                wordApp = value;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        public _Document Document</div><div class="line">        &#123;</div><div class="line">            get</div><div class="line">            &#123;</div><div class="line">                return wordDoc;</div><div class="line">            &#125;</div><div class="line">            set</div><div class="line">            &#123;</div><div class="line">                wordDoc = value;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        //通过模板创建新文档</div><div class="line">        public void CreateNewDocument(string filePath)</div><div class="line">        &#123;</div><div class="line">            killWinWordProcess(); </div><div class="line">             wordApp = new ApplicationClass();</div><div class="line">            wordApp.DisplayAlerts = WdAlertLevel.wdAlertsNone;</div><div class="line">            wordApp.Visible = false;</div><div class="line">            object missing = System.Reflection.Missing.Value;</div><div class="line">            object templateName = filePath;</div><div class="line">            wordDoc = wordApp.Documents.Open(ref templateName, ref missing,</div><div class="line">                ref missing, ref missing, ref missing, ref missing, ref missing,</div><div class="line">                ref missing, ref missing, ref missing, ref missing, ref missing,</div><div class="line">                ref missing, ref missing, ref missing, ref missing);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        //保存新文件</div><div class="line">        public void SaveDocument(string filePath)</div><div class="line">        &#123;</div><div class="line">            object fileName = filePath;</div><div class="line">            object format = WdSaveFormat.wdFormatDocument;//保存格式</div><div class="line">            object miss = System.Reflection.Missing.Value;</div><div class="line">            wordDoc.SaveAs(ref fileName, ref format, ref miss,</div><div class="line">                ref miss, ref miss, ref miss, ref miss,</div><div class="line">                ref miss, ref miss, ref miss, ref miss,</div><div class="line">                ref miss, ref miss, ref miss, ref miss,</div><div class="line">                ref miss);</div><div class="line">            //关闭wordDoc，wordApp对象</div><div class="line">            object SaveChanges = WdSaveOptions.wdSaveChanges;</div><div class="line">            object OriginalFormat = WdOriginalFormat.wdOriginalDocumentFormat;</div><div class="line">            object RouteDocument = false;</div><div class="line">            wordDoc.Close(ref SaveChanges, ref OriginalFormat, ref RouteDocument);</div><div class="line">            wordApp.Quit(ref SaveChanges, ref OriginalFormat, ref RouteDocument);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        //给表格插入rows行,n为表格的序号</div><div class="line">        public void AddRow(int n, int rows)</div><div class="line">        &#123;</div><div class="line">            object miss = System.Reflection.Missing.Value;</div><div class="line">            Microsoft.Office.Interop.Word.Table table = wordDoc.Content.Tables[n];</div><div class="line">            for (int i = 0; i &lt; rows; i++)</div><div class="line">            &#123;</div><div class="line">                table.Rows.Add(ref miss);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">		</div><div class="line">	//在第n个表格的rows行前面插入新行,</div><div class="line">         public void AddNewRow(int n,int rows)</div><div class="line">        &#123;</div><div class="line">            object beforeRow = wordDoc.Tables[n].Rows[rows];</div><div class="line">            Microsoft.Office.Interop.Word.Table table = wordDoc.Content.Tables[n];</div><div class="line"></div><div class="line">            table.Rows.Add(beforeRow);</div><div class="line">          </div><div class="line">        &#125;</div><div class="line">    // 杀掉winword.exe进程</div><div class="line">        public void killWinWordProcess()</div><div class="line">        &#123;</div><div class="line">            System.Diagnostics.Process[] processes = System.Diagnostics.Process.GetProcessesByName(&quot;WINWORD&quot;);</div><div class="line">            foreach (System.Diagnostics.Process process in processes)</div><div class="line">            &#123;</div><div class="line">                bool b = process.MainWindowTitle == &quot;&quot;;</div><div class="line">                if (process.MainWindowTitle == &quot;&quot;)</div><div class="line">                &#123;</div><div class="line">                    process.Kill();</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在上面的 <code>AddNewRow(int n,int rows)</code>函数中，可以根据实际情况设置要插入第几个表格和在第几行前面插入新行。<br>调用代码：<br><img src="/2017/10/25/通过C-向Word文档的表格中的任一行增加新行/code.jpg" alt="code"></p>
<p>插入前：<br><img src="/2017/10/25/通过C-向Word文档的表格中的任一行增加新行/before.jpg" alt="before"></p>
<p>插入后：<br><img src="/2017/10/25/通过C-向Word文档的表格中的任一行增加新行/after.jpg" alt="after"></p>
<p>可以根据实际情况设置循环的数量 ，实现动态添加。</p>
]]></content>
      
        <categories>
            
            <category> 项目 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> C# </tag>
            
            <tag> 遇到的坑 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[将图片以二进制流方式存入数据库和从数据库读取(c#,oracle 11g)]]></title>
      <url>/2017/10/23/%E5%B0%86%E5%9B%BE%E7%89%87%E4%BB%A5%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%B5%81%E6%96%B9%E5%BC%8F%E5%AD%98%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93-c-oracle-11g/</url>
      <content type="html"><![CDATA[<script src="/js/src/jquery-3.2.1.min.js"></script>


<p>在项目的实施过程中，遇到了一个问题：项目需求网页前端读取一张照片，以二进制的方式存入oracle数据库中。这个问题，用了一天的时间解决，所以写此文记录一下。<br>      在网上搜了一圈，并加以实施发现实施过程如下：前台获取图片路径，用FileReader读取后，可以转换为base64编码的字符串，然后通过ajax 将base64格式编码字符串传到后台，C#读取前台传来的字符串，将其转化存到byte[] 数组中，最后写入数据库。</p>
<p>下面为实现代码和预览结果：<br>前端：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">&lt;div class=&quot;form-group&quot;&gt;</div><div class="line">      &lt;label class=&quot;col-sm-2 control-label&quot; for=&quot;PHOTO&quot;&gt;个人照片&lt;/label&gt;</div><div class="line">      &lt;div id=&quot;imgForm&quot; class=&quot;col-sm-10&quot; style=&quot;margin:4px auto 5px auto&quot;&gt;</div><div class="line">      &lt;p id=&quot;imagesize&quot; style=&quot;display:none&quot;&gt;&lt;/p&gt;//上传图片后可以显示图片尺寸</div><div class="line">      &lt;img id=&quot;preview&quot; /&gt;</div><div class="line">      &lt;br /&gt;</div><div class="line">	  &lt;input type=&quot;file&quot; name=&quot;file&quot; id=&quot;img&quot; /&gt;//&lt;input&gt;标签有type=&quot;file&quot;用来上传文件</div><div class="line">      &lt;/div&gt;</div><div class="line">&lt;/div&gt;</div></pre></td></tr></table></figure></p>
<p>预览结果：</p>
<p>  <label class="col-sm-2 control-label" for="PHOTO">个人照片</label><br>   <div id="imgForm"><br>    <p id="imagesize"></p><br>    <img id="preview"><br>      <br><br>      <input type="file" name="file" id="img"><br>      </div></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"> var imgFile;</div><div class="line"> var justify = &quot;1&quot;;//用来判断图片大小是否超出尺寸，1代表没有超出，0代表超出</div><div class="line"> document.getElementById(&apos;img&apos;).onchange = function () &#123;//判断是否支持FileReader</div><div class="line">    if (window.FileReader) &#123;</div><div class="line">    var reader = new FileReader();</div><div class="line">    &#125; else &#123;</div><div class="line">        alert(&quot;不支持图片预览功能，如需该功能请升级！&quot;);</div><div class="line">    &#125;</div><div class="line">    justify = &quot;1&quot;;</div><div class="line">    var img = event.target.files[0];</div><div class="line">    // 判断是否图片</div><div class="line">    if (!img) &#123;</div><div class="line">    return false;</div><div class="line">    &#125;</div><div class="line">    // 判断图片格式</div><div class="line">    if (!(img.type.indexOf(&apos;image&apos;) == 0 &amp;&amp; img.type &amp;&amp; /\.(?:jpg|jpeg)$/.test(img.name))) &#123;</div><div class="line">    alert(&apos;图片只能是jpg jpeg&apos;);</div><div class="line">    return false;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">   var reader = new FileReader();</div><div class="line">   reader.readAsDataURL(img);</div><div class="line">   reader.onload = function (e) &#123;</div><div class="line">   imgFile = e.target.result;</div><div class="line">   //获取图片dom</div><div class="line">   var img1 = document.getElementById(&quot;preview&quot;);</div><div class="line">    //图片路径设置为读取的图片</div><div class="line">   img1.src = e.target.result;</div><div class="line">   var imgwidth = img1.offsetWidth;//获取图片宽高</div><div class="line">   var imgheight = img1.offsetHeight;</div><div class="line">   var size = document.getElementById(&apos;imagesize&apos;);</div><div class="line">   size.style.display = &quot;block&quot;;</div><div class="line">   size.innerHTML = imgwidth + &quot;×&quot; + imgheight;</div><div class="line">   if (imgwidth &gt; 600 || imgheight &gt; 800) &#123;</div><div class="line">   justify = &quot;0&quot;;</div><div class="line">   alert(&quot;图片尺寸不应大于600×800&quot;);</div><div class="line">   &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这时候写一个button 触发函数通过ajax来上传照片到后台：</p>
<button id="btn2" type="submit" onclick="AddExperts()">提交</button>


<p><br></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">&lt;div class=&quot;box-footer&quot;&gt;</div><div class="line">      &lt;div class=&quot;box-tools col-sm-2&quot;&gt;</div><div class="line">              &lt;div class=&quot;has-feedback&quot;&gt;</div><div class="line">                        &lt;button id=&quot;btn2&quot; type=&quot;submit&quot; class=&quot;btn btn-primary&quot; onclick=&quot;AddExperts()&quot;&gt;提交&lt;/button&gt;</div><div class="line">              &lt;/div&gt;</div><div class="line">    &lt;/div&gt;</div><div class="line">&lt;/div&gt;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">function AddExperts() &#123;</div><div class="line">   </div><div class="line">    var postimg = imgFile;</div><div class="line">    $.ajax(&#123;</div><div class="line">                type: &quot;POST&quot;,</div><div class="line">                async: false,</div><div class="line">                url: &quot;ashx/zlgly-zjgl-add.ashx&quot;,</div><div class="line">                contentType: &quot;application/x-www-form-urlencoded; charset=UTF-8&quot;,</div><div class="line">                data: &#123;img: postimg, JUSTIFY: justify &#125;,</div><div class="line">    timeout: 1000,</div><div class="line">    cache: false,</div><div class="line">    success: function (result) &#123;</div><div class="line">                    if (result) &#123;</div><div class="line">                        alert(result);</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">            &#125;);</div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>以一张照片为例，如果上传了一张jpg或者jepg格式的图片，postimg为很长的一串字符串。<br><img src="/2017/10/23/将图片以二进制流方式存入数据库-c-oracle-11g/base64.jpg" alt="base64"></p>
<p>至此前端的操作就到此结束了，下面进入后台的.ashx文件查看相关代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">using System;</div><div class="line">using System.Data;</div><div class="line">using System.Configuration;</div><div class="line">using System.Web;</div><div class="line">using Oracle.ManagedDataAccess.Client;</div><div class="line">public class 后台文件 : IHttpHandler</div><div class="line">&#123;</div><div class="line"></div><div class="line">    public void ProcessRequest(HttpContext context)</div><div class="line">    &#123;</div><div class="line">        context.Response.ContentType = &quot;text/plain&quot;;</div><div class="line">        //从前端读取数据</div><div class="line"></div><div class="line">      </div><div class="line">        string myFile = context.Request.Form[&quot;img&quot;];</div><div class="line">        string text = myFile.Substring(23);//截取base64字符串23个字符之后的内容</div><div class="line">        string JUSTIFY = context.Request.Form[&quot;JUSTIFY&quot;];</div><div class="line"></div><div class="line">        byte[] imageBytes = Convert.FromBase64String(text);//将base64字符串转化为byte[] 格式</div><div class="line">        if (JUSTIFY == &quot;0&quot;)</div><div class="line">        &#123;</div><div class="line">            context.Response.Write(&quot;图片大小超出尺寸&quot;);</div><div class="line">            context.Response.End();</div><div class="line">        &#125;</div><div class="line">        else</div><div class="line">        &#123;</div><div class="line">            //与数据库连接</div><div class="line">            string myvar = ConfigurationManager.ConnectionStrings[&quot;Conn&quot;].ToString();</div><div class="line">            OracleConnection conn = new OracleConnection(myvar);</div><div class="line">            try</div><div class="line">            &#123;</div><div class="line">                conn.Open();</div><div class="line">            &#125;</div><div class="line">            catch (Exception ex)</div><div class="line">            &#123;</div><div class="line">                context.Response.Write(ex.Message);</div><div class="line">                context.Response.End();</div><div class="line">            &#125;</div><div class="line"></div><div class="line">          string insertimg = &quot;update EXPERTS SET IMAGE=:imageBytes where 条件=&apos;&quot; + 条件 + &quot;&apos;&quot;;</div><div class="line">                OracleCommand cmd = new OracleCommand(insertimg, conn);</div><div class="line">                cmd.Parameters.Add(new OracleParameter(&quot;imageBytes&quot;, OracleDbType.Blob));</div><div class="line">                cmd.Parameters[&quot;imageBytes&quot;].Value = imageBytes;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里向c#数据库的blob中写入图片，在网上搜了一段代码，也可以用，思路更清晰：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">//打开数据库</div><div class="line">String   connectionstring = &quot;Data Source=apts_test;user id=aptstest;password=test&quot;;</div><div class="line">OracleConnection  con   =new OracleConnection(connectionstring);</div><div class="line">con.Open();</div><div class="line">//向指定记录添加blob字段，例如图片</div><div class="line">private void add_blob()</div><div class="line"> &#123; </div><div class="line">	String sql = @&quot;update testxx set image=:myimage  where ID=:myid&quot;;//在testxx表中有个字段叫image是blob类型的注意中的冒号，通过myid制定记录</div><div class="line">	OracleCommand cmd = new OracleCommand(sql, con);</div><div class="line">	cmd.Parameters.Add(new OracleParameter(&quot;myimage&quot;, 	OracleType.Blob));//给这个两个参数赋值myimage和myid</div><div class="line">	cmd.Parameters.Add(new OracleParameter(&quot;myid&quot;, OracleType.VarChar));</div><div class="line">	cmd.Parameters[&quot;myid&quot;].Value = &quot;1&quot;;</div><div class="line"> 	//给image字段赋值字节数组</div><div class="line"> 	FileStream fs     =  File.OpenRead(&quot;D:/ 2.jpg&quot;);</div><div class="line">	byte[] imagebyte  = new byte[fs.Length];</div><div class="line">	fs.Read(imagebyte, 0, (int)fs.Length);</div><div class="line">	cmd.Parameters[&quot;myimage&quot;].Value = imagebyte;</div><div class="line">	 try</div><div class="line">	 &#123;</div><div class="line">	  int result = cmd.ExecuteNonQuery();</div><div class="line"> 	 if (result &lt; 1)</div><div class="line">      System.Console.WriteLine(&quot;success&quot;);</div><div class="line">	  else</div><div class="line">      System.Console.WriteLine(&quot;error&quot;);</div><div class="line">	&#125;</div><div class="line">	catch (Exception e1)</div><div class="line">	&#123;             &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在pl/sql developer中查看上传结果可以看到已经上传成功了：<br><img src="/2017/10/23/将图片以二进制流方式存入数据库-c-oracle-11g/上传结果.jpg" alt="上传结果"></p>
<p>当然因为这里在后台没有判断照片的尺寸，后期会进行更新。</p>
<p>当然，读取的方式类似。将blob中byte[] 格式转换为base64 ，但这个时候要注意开始时是把base64最前面的23个字符给去掉了，这时候要加上。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">DataTable td = new DataTable(&quot;Name&quot;);//创建datatable来存放</div><div class="line">td.Columns.Add(&quot;IMAGE&quot;, Type.GetType(&quot;System.String&quot;));//增加一列，列名为IMAGE</div><div class="line">td.Rows.Add();//增加一行</div><div class="line">string sql = &quot;SELECT * FROM 表名 WHERE 条件 &quot;+ 条件 + &quot;&apos;&quot;;</div><div class="line">OracleCommand cmd = new OracleCommand(sql, conn);</div><div class="line">cmd.CommandType = System.Data.CommandType.Text;</div><div class="line">OracleDataReader  = cmd.ExecuteReader();</div><div class="line">   if (sdr.Read())</div><div class="line">       &#123;           </div><div class="line">           if(!sdr.IsDBNull(12))</div><div class="line">           &#123;</div><div class="line">           byte[] img =(byte[])sdr[&quot;IMAGE&quot;];</div><div class="line">           string  pic =&quot;data:image/jpeg;base64,&quot;+ Convert.ToBase64String(img);//加上字符串</div><div class="line">           td.Rows[0][&quot;IMAGE&quot;] = pic;</div><div class="line">           &#125;</div><div class="line">           </div><div class="line">           string jsonresult = JsonConvert.SerializeObject(td);</div><div class="line">           context.Response.Write(jsonresult);//传到前台</div><div class="line">           context.Response.End();</div><div class="line">       &#125;</div><div class="line">       else</div><div class="line">       &#123;</div><div class="line">           context.Response.Write(&quot;1&quot;);</div><div class="line">           context.Response.End();</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>这时候传到前台的还是base64字符串，而且img标签可以自动将base6码放入 img的 src=” “‘中,html会自动转码，至此就实现了图片导数据库和数据库到图片的整套读取方法了。</p>
]]></content>
      
        <categories>
            
            <category> 项目 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> C# </tag>
            
            <tag> 遇到的坑 </tag>
            
            <tag> 数据库 </tag>
            
            <tag> oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[初级算法]]></title>
      <url>/2017/09/02/%E5%88%9D%E7%BA%A7%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p> 因为是刚开始学习JS，之前对算法的学习也很少，先从最基本的算法开始写起。基本都是FCC题目上的算法。</p>
<h1 id="计算一个整数的阶乘"><a href="#计算一个整数的阶乘" class="headerlink" title="计算一个整数的阶乘"></a>计算一个整数的阶乘</h1><h2 id="算法1"><a href="#算法1" class="headerlink" title="算法1"></a>算法1</h2><p>普通方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">function factorialize(num) &#123;</div><div class="line">  var number=1;</div><div class="line">  while(num&gt;=1)&#123;</div><div class="line">    number*=num;</div><div class="line">	num--;</div><div class="line">	&#125;</div><div class="line">	return number;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">  factorialize(10);  //3628800</div><div class="line">  factorialize(20); // 2432902008176640000</div><div class="line">  factorialize(0); //1</div></pre></td></tr></table></figure>
<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><p>下面是递归的方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">function factorialize(num) &#123;</div><div class="line">  if (num === 0)&#123;</div><div class="line">  return 1;</div><div class="line">  &#125;</div><div class="line">  else&#123;</div><div class="line">    return num * factorialize(num - 1);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">factorialize(10);  //3628800</div><div class="line">factorialize(20); // 2432902008176640000</div><div class="line">factorialize(0); //1</div></pre></td></tr></table></figure>
<hr>
<h1 id="分割数组"><a href="#分割数组" class="headerlink" title="分割数组"></a>分割数组</h1><p>把一个数组arr按照指定的数组大小size分割成若干个数组块。</p>
<p>例如:chunk([1,2,3,4],2)=[[1,2],[3,4]];</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">function chunk(arr, size) &#123;</div><div class="line">  var arr2=[];</div><div class="line">  for(var i=0;i&lt;arr.length;i=i+size)&#123;</div><div class="line">    arr2.push(arr.slice(i,i+size));</div><div class="line">	&#125;</div><div class="line">	return arr2;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">chunk([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;], 2);</div><div class="line">chunk([0, 1, 2, 3, 4, 5, 6], 3);  // [[0, 1, 2], [3, 4, 5], [6]]</div><div class="line">chunk([0, 1, 2, 3, 4, 5, 6, 7, 8], 4);  // [[0, 1, 2, 3], [4, 5, 6, 7], [8]]</div></pre></td></tr></table></figure>
<hr>
<h1 id="截断数组"><a href="#截断数组" class="headerlink" title="截断数组"></a>截断数组</h1><p>截断数组的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">function slasher(arr, howMany) &#123;</div><div class="line">  arr.splice(0,howMany); </div><div class="line">  return arr;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">slasher([1, 2, 3], 2);</div></pre></td></tr></table></figure>
<blockquote>
<p>splice() 方法通过删除现有元素和/或添加新元素来更改一个数组的内容。<br>splice() 方法与 slice() 方法的作用是不同的，splice() 方法会直接对数组进行修改。</p>
</blockquote>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">var myFish = [&apos;angel&apos;, &apos;clown&apos;, &apos;mandarin&apos;, &apos;sturgeon&apos;];</div><div class="line">myFish.splice(2, 0, &apos;drum&apos;); // 在索引为2的位置插入&apos;drum&apos;</div><div class="line">// myFish 变为 [&quot;angel&quot;, &quot;clown&quot;, &quot;drum&quot;, &quot;mandarin&quot;, &quot;sturgeon&quot;]</div><div class="line">myFish.splice(2, 1); // 从索引为2的位置删除一项（也就是&apos;drum&apos;这一项）</div><div class="line">// myFish 变为 [&quot;angel&quot;, &quot;clown&quot;, &quot;mandarin&quot;, &quot;sturgeon&quot;]</div></pre></td></tr></table></figure>
<hr>
<h1 id="比较字符串"><a href="#比较字符串" class="headerlink" title="比较字符串"></a>比较字符串</h1><p>比较字符串</p>
<p>如果数组第一个字符串元素包含了第二个字符串元素的所有字符，函数返回true。</p>
<p>举例，[“hello”, “Hello”]应该返回true，因为在忽略大小写的情况下，第二个字符串的所有字符都可以在第一个字符串找到。</p>
<p>[“hello”, “hey”]应该返回false，因为字符串”hello”并不包含字符”y”。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">function mutation(arr) &#123;</div><div class="line">  var arr2=arr[1].toLowerCase().split(&quot;&quot;);// 先把后面的字符串拆分成数组</div><div class="line">  for(var i=0;i&lt;arr2.length;i++)&#123;</div><div class="line">    if(arr[0].toLowerCase().indexOf(arr2[i])&lt;0)&#123; //将前面的数组转化为小写后与后面拆分的数组的每一个字母比较， indexOf不包含的情况会返回-1</div><div class="line">      return false;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  return true;</div><div class="line">  </div><div class="line">&#125;</div><div class="line"></div><div class="line">mutation([&quot;hello&quot;, &quot;hey&quot;]);//false</div><div class="line">mutation([&quot;hello&quot;, &quot;Hello&quot;]);//true</div><div class="line">mutation([&quot;zyxwvutsrqponmlkjihgfedcba&quot;, &quot;qrstu&quot;]);//true</div></pre></td></tr></table></figure>
<blockquote>
<p>split() 方法使用指定的分隔符字符串将一个String对象分割成字符串数组，以将字符串分隔为子字符串，以确定每个拆分的位置。</p>
</blockquote>
<p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/String/split" target="_blank" rel="external">split()</a></p>
<blockquote>
<p>str.split([separator[, limit]])<br>separator<br>指定表示每个拆分应发生的点的字符串。separator 可以是一个字符串或正则表达式。 如果纯文本分隔符包含多个字符，则必须找到整个字符串来表示分割点。如果在str中省略或不出现分隔符，则返回的数组包含一个由整个字符串组成的元素。如果分隔符为空字符串，则将str原字符串中每个字符的数组形式返回。<br>limit<br>一个整数，限定返回的分割片段数量。当提供此参数时，split 方法会在指定分隔符的每次出现时分割该字符串，但在限制条目已放入数组时停止。如果在达到指定限制之前达到字符串的末尾，它可能仍然包含少于限制的条目。新数组中不返回剩下的文本。</p>
</blockquote>
<hr>
<h1 id="过滤数组假值"><a href="#过滤数组假值" class="headerlink" title="过滤数组假值"></a>过滤数组假值</h1><p>删除数组中的所有假值。</p>
<p>在JavaScript中，假值有false、null、0、””、undefined 和 NaN。</p>
<p>参考：<a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Boolean" target="_blank" rel="external">Boolean Objects</a><br>          <a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Array/filter" target="_blank" rel="external">Array.filter()</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">function bouncer(arr) &#123;</div><div class="line">  return arr.filter(isBad);</div><div class="line">  function isBad(params)&#123; </div><div class="line">   var result = Boolean(params);</div><div class="line">   return result; &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">bouncer([7, &quot;ate&quot;, &quot;&quot;, false, 9]);//[7, &quot;ate&quot;, 9]</div><div class="line">bouncer([false, null, 0, NaN, undefined, &quot;&quot;]);// []</div></pre></td></tr></table></figure>
<h1 id="数组排序并找出元素索引"><a href="#数组排序并找出元素索引" class="headerlink" title="数组排序并找出元素索引"></a>数组排序并找出元素索引</h1><p>先给数组排序，然后找到指定的值在数组的位置，最后返回位置对应的索引。</p>
<p>举例：where([1,2,3,4], 1.5) 应该返回 1。因为1.5插入到数组[1,2,3,4]后变成[1,1.5,2,3,4]，而1.5对应的索引值就是1。</p>
<p>同理，where([20,3,5], 19) 应该返回 2。因为数组会先排序为 [3,5,20]，19插入到数组[3,5,20]后变成[3,5,19,20]，而19对应的索引值就是2。</p>
<p>这题的思路就比较简单了，先把后面的数加到前面的数组中，然后对加入新数的数组进行排序，最后找到新加入的数字的索引即可。下面是我自己写的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">function where(arr, num) &#123;</div><div class="line">  var arr1=[];</div><div class="line">  arr.push(num);</div><div class="line">  arr.sort( function(a,b)&#123;</div><div class="line">    return a-b;</div><div class="line">  &#125;);</div><div class="line">  for(var i=0;i&lt;arr.length;i++)&#123;</div><div class="line">    if(arr[i]===num)&#123;</div><div class="line">      return i;</div><div class="line">    &#125;    </div><div class="line">  &#125;  </div><div class="line">&#125;</div><div class="line"></div><div class="line">where([40, 60], 50); //1</div><div class="line">where([10, 20, 30, 40, 50], 35);//3</div><div class="line">where([10, 20, 30, 40, 50], 30);// 2</div><div class="line">where([40, 60], 50);// 1</div><div class="line">where([3, 10, 5], 3);// 0</div><div class="line">where([5, 3, 20, 3], 5);// 2</div><div class="line">where([2, 20, 10], 19);// 2</div><div class="line">where([2, 5, 10], 15);// 3</div></pre></td></tr></table></figure>
<p>后面再网上看到了一个其他的方法，可以用 <strong>Array.indexOf()</strong> 方法直接获取元素的索引值，其他的思路一样。代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">function where(arr, num) &#123;</div><div class="line">  var arr1=[];</div><div class="line">  arr.push(num);</div><div class="line">  arr.sort( function(a,b)&#123;</div><div class="line">    return a-b;</div><div class="line">  &#125;);</div><div class="line"> return arr.indexOf(num);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="凯撒密码"><a href="#凯撒密码" class="headerlink" title="凯撒密码"></a>凯撒密码</h1><p>下面我们来介绍风靡全球的凯撒密码Caesar cipher，又叫移位密码。</p>
<p>移位密码也就是密码中的字母会按照指定的数量来做移位。</p>
<p>一个常见的案例就是ROT13密码，字母会移位13个位置。由’A’ ↔ ‘N’, ‘B’ ↔ ‘O’，以此类推。</p>
<p>写一个ROT13函数，实现输入加密字符串，输出解密字符串。</p>
<p>所有的字母都是大写，不要转化任何非字母形式的字符(例如：空格，标点符号)，遇到这些特殊字符，跳过它们。</p>
<p>可能用到的内容：<br><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt" target="_blank" rel="external">String.charCodeAt()</a><br><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/String/fromCharCode" target="_blank" rel="external">String.fromCharCode()</a><br><a href="http://ascii.911cha.com/" target="_blank" rel="external">ASCII码对照表</a></p>
<p>大写字母的对应关系如下：<br><code>ABCDEFGHIJKLMNOPQRSTUVWXYZ</code><br><code>NOPQRSTUVWXYZABCDEFGHIJKLM</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">function rot13(str) &#123; </div><div class="line">  var arr=[];</div><div class="line">  for(var i=0;i&lt;str.length;i++)&#123;  //遍历字符串的每一个字符</div><div class="line">  </div><div class="line">  	//其他字符等非大写字母字符  	</div><div class="line">  	if(str.charCodeAt(i)&lt;65||str.charCodeAt(i)&gt;90)&#123;</div><div class="line">  		arr.push(String.fromCharCode(str.charCodeAt(i)));</div><div class="line">  	&#125;</div><div class="line">  	//大写字母的ASCII码表对应的数值为65-90</div><div class="line">  	else if(str.charCodeAt(i)&gt;77)&#123;</div><div class="line">  		arr.push(String.fromCharCode(str.charCodeAt(i)-13));</div><div class="line">  	&#125;</div><div class="line">  	else&#123;</div><div class="line">  		arr.push(String.fromCharCode(str.charCodeAt(i)+13));</div><div class="line">  	&#125;</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  return arr.join(&quot;&quot;);</div><div class="line">&#125;</div><div class="line"></div><div class="line">console.log(rot13(&quot;SERR PBQR PNZC&quot;));  // FREE CODE CAMP</div><div class="line"></div><div class="line">rot13(&quot;SERR CVMMN!&quot;));  //  &quot;FREE PIZZA!&quot;</div><div class="line">rot13(&quot;SERR YBIR?&quot;) );  //  &quot;FREE LOVE?&quot;</div><div class="line">rot13(&quot;GUR DHVPX OEBJA QBT WHZCRQ BIRE GUR YNML SBK.&quot;));  // &quot;THE QUICK BROWN DOG JUMPED OVER THE LAZY FOX.&quot;</div></pre></td></tr></table></figure>
<h1 id="返回给定的两个数组中不同的值"><a href="#返回给定的两个数组中不同的值" class="headerlink" title="返回给定的两个数组中不同的值"></a>返回给定的两个数组中不同的值</h1><p>Diff Two Arrays<br>比较两个数组，然后返回一个新数组，该数组的元素为两个给定数组中所有独有的数组元素。换言之，返回两个数组的差异。</p>
<p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Array/indexOf" target="_blank" rel="external">Array.indexOf()</a></p>
<p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Array/concat" target="_blank" rel="external">Array.concat()</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">function diff(arr1, arr2) &#123;</div><div class="line">  var newArr = [];</div><div class="line">  // Same, same; but different.</div><div class="line">  var arr3 = [];  </div><div class="line">  for (var i=0;i&lt;arr1.length;i++) &#123;  </div><div class="line">    if(arr2.indexOf(arr1[i]) === -1)     </div><div class="line">      arr3.push(arr1[i]);  </div><div class="line">  &#125;  </div><div class="line">   var arr4 = [];  </div><div class="line">  for (var j=0;j&lt;arr2.length;j++) &#123;  </div><div class="line">    if(arr1.indexOf(arr2[j]) === -1)  </div><div class="line">      arr4.push(arr2[j]);  </div><div class="line">  &#125;  </div><div class="line">   newArr = arr3.concat(arr4);  </div><div class="line">  return newArr;</div><div class="line">&#125;</div><div class="line"></div><div class="line">diff([1, 2, 3, 5], [1, 2, 3, 4, 5]);//[4]</div><div class="line">[1, &quot;calf&quot;, 3, &quot;piglet&quot;], [1, &quot;calf&quot;, 3, 4];// [&quot;piglet&quot;, 4]</div><div class="line">[], [&quot;snuffleupagus&quot;, &quot;cookie monster&quot;, &quot;elmo&quot;] ;// [&quot;snuffleupagus&quot;, &quot;cookie monster&quot;, &quot;elmo&quot;]</div><div class="line">[1, &quot;calf&quot;, 3, &quot;piglet&quot;], [7, &quot;filly&quot;];// [1, &quot;calf&quot;, 3, &quot;piglet&quot;, 7, &quot;filly&quot;]</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> 算法 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 算法 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/08/21/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
</search>
